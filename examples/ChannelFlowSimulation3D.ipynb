{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "import lettuce\n",
    "import lettuce as lt\n",
    "from lettuce import D3Q19, Lattice, UnitConversion, BGKCollision, StandardStreaming, Simulation, IncompressibleKineticEnergy, WallQuantities, SimulationHWBB, GlobalMeanUXReporter, AdaptiveForce\n",
    "from argparse import ArgumentParser, ArgumentDefaultsHelpFormatter\n",
    "import csv"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-23T12:46:04.479288648Z",
     "start_time": "2025-06-23T12:46:03.036531704Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class WallQuantitiesInternal:\n",
    "    def __init__(\n",
    "        self,\n",
    "        lattice,\n",
    "        flow,\n",
    "        molecular_viscosity,\n",
    "        y_lattice=1.0,\n",
    "        wall='bottom',\n",
    "        kappa=0.41,\n",
    "        B=5.2,\n",
    "        max_iter=100,\n",
    "        tol=1e-8,\n",
    "        use_smagorinsky=False,\n",
    "        smagorinsky_collision_instance=None\n",
    "    ):\n",
    "        self.lattice = lattice\n",
    "        self.flow = flow\n",
    "        self.nu = molecular_viscosity\n",
    "        self.y = y_lattice\n",
    "        self.wall = wall\n",
    "        self.kappa = kappa\n",
    "        self.B = B\n",
    "        self.max_iter = max_iter\n",
    "        self.tol = tol\n",
    "        self.normal_axis = 1  # y-Achse\n",
    "\n",
    "        self.use_smagorinsky = use_smagorinsky\n",
    "        if self.use_smagorinsky:\n",
    "            if smagorinsky_collision_instance is None:\n",
    "                raise ValueError(\"Smagorinsky collision instance required if use_smagorinsky=True.\")\n",
    "            self.smagorinsky_collision = smagorinsky_collision_instance\n",
    "\n",
    "    def spalding_law(self, y_plus_grid_dist, u_mag_wall_parallel, nu_effective):\n",
    "        y_plus_grid_dist = torch.tensor(y_plus_grid_dist, device=u_mag_wall_parallel.device, dtype=u_mag_wall_parallel.dtype)\n",
    "        u_plus = (y_plus_grid_dist * u_mag_wall_parallel / nu_effective).clamp(min=1e-4).detach().clone().requires_grad_(False)\n",
    "\n",
    "        for _ in range(self.max_iter):\n",
    "            ku = self.kappa * u_plus\n",
    "            exp_ku = torch.exp(ku)\n",
    "            spalding_term = u_plus + torch.exp(torch.tensor(-self.kappa * self.B, device=u_plus.device, dtype=u_plus.dtype)) * (\n",
    "                exp_ku - 1 - ku - 0.5 * ku**2 - (1/6) * ku**3\n",
    "            )\n",
    "            rhs = (y_plus_grid_dist * u_mag_wall_parallel) / (nu_effective * u_plus.clamp(min=1e-8))\n",
    "            f_eq_solve = spalding_term - rhs\n",
    "\n",
    "            d_spalding_term = 1 + torch.exp(torch.tensor(-self.kappa * self.B, device=u_plus.device, dtype=u_plus.dtype)) * (\n",
    "                self.kappa * exp_ku - self.kappa - self.kappa**2 * u_plus - 0.5 * self.kappa**3 * u_plus**2\n",
    "            )\n",
    "            d_rhs = - (y_plus_grid_dist * u_mag_wall_parallel) / (nu_effective * u_plus.clamp(min=1e-8)**2)\n",
    "            df_eq_solve = d_spalding_term - d_rhs\n",
    "\n",
    "            delta = f_eq_solve / torch.where(torch.abs(df_eq_solve) < 1e-10, torch.tensor(1e-10, device=f_eq_solve.device), df_eq_solve)\n",
    "            u_plus = (u_plus - delta).clamp(min=1e-4)\n",
    "\n",
    "            if torch.max(torch.abs(delta)) < self.tol:\n",
    "                break\n",
    "        return u_plus\n",
    "\n",
    "    def __call__(self, f_full_grid):\n",
    "        rho_full = self.lattice.rho(f_full_grid)\n",
    "        u_full = self.lattice.u(f_full_grid)\n",
    "\n",
    "        if rho_full.ndim == self.lattice.D + 1 and rho_full.shape[0] == 1:\n",
    "            rho_full = rho_full.squeeze(0)\n",
    "        if u_full.ndim == self.lattice.D + 1 and u_full.shape[1] == 1:\n",
    "            u_full = u_full.squeeze(1)\n",
    "\n",
    "        grid_spatial_dims = list(range(self.lattice.D))\n",
    "        spatial_idx_slice = [slice(None)] * self.lattice.D\n",
    "        spatial_idx_slice[self.normal_axis] = 1 if self.wall == \"bottom\" else -2\n",
    "\n",
    "        rho_f = rho_full[tuple(spatial_idx_slice)].flatten()\n",
    "        u_x_f = u_full[0][tuple(spatial_idx_slice)].flatten()\n",
    "        u_y_f = u_full[1][tuple(spatial_idx_slice)].flatten()\n",
    "        u_z_f = u_full[2][tuple(spatial_idx_slice)].flatten() if self.lattice.D == 3 else torch.zeros_like(u_x_f)\n",
    "\n",
    "        u_mag_wall_parallel = torch.sqrt(u_x_f**2 + u_z_f**2).clamp(min=1e-10)\n",
    "\n",
    "        if self.use_smagorinsky:\n",
    "            tau_eff_scalar = self.smagorinsky_collision.tau_eff\n",
    "            shape = u_full[0].shape\n",
    "            tau_eff_full_grid = torch.full(shape, tau_eff_scalar, device=u_full.device, dtype=u_full.dtype)\n",
    "            nu_eff_full_grid = (tau_eff_full_grid - 0.5) / 3.0\n",
    "            nu_eff_wall_layer = nu_eff_full_grid[tuple(spatial_idx_slice)].flatten()\n",
    "        else:\n",
    "            nu_eff_wall_layer = torch.full_like(u_mag_wall_parallel, self.nu)\n",
    "\n",
    "        u_plus = self.spalding_law(self.y, u_mag_wall_parallel, nu_eff_wall_layer)\n",
    "        u_tau = (u_mag_wall_parallel / u_plus).clamp(min=1e-8)\n",
    "        tau_w = rho_f * u_tau**2\n",
    "\n",
    "        safe_u_mag = torch.where(u_mag_wall_parallel < 1e-10, torch.tensor(1.0, device=u_mag_wall_parallel.device, dtype=u_mag_wall_parallel.dtype), u_mag_wall_parallel)\n",
    "        tau_x = - (u_x_f / safe_u_mag) * tau_w\n",
    "        tau_z = - (u_z_f / safe_u_mag) * tau_w\n",
    "\n",
    "        tau_x_wall = torch.zeros_like(u_full[0])\n",
    "        tau_z_wall = torch.zeros_like(u_full[2] if self.lattice.D == 3 else u_full[0])\n",
    "\n",
    "        if self.lattice.D == 3:\n",
    "            target_shape_slice = tau_x_wall[tuple(spatial_idx_slice)].shape\n",
    "            tau_x_wall[tuple(spatial_idx_slice)] = tau_x.reshape(target_shape_slice)\n",
    "            tau_z_wall[tuple(spatial_idx_slice)] = tau_z.reshape(target_shape_slice)\n",
    "        else:\n",
    "            raise ValueError(\"Only 3D supported for this current implementation of WallQuantitiesInternal.\")\n",
    "\n",
    "        return {\n",
    "            \"tau_x\": tau_x_wall,\n",
    "            \"tau_z\": tau_z_wall,\n",
    "            \"u_tau\": u_tau\n",
    "        }\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-23T12:46:04.495816973Z",
     "start_time": "2025-06-23T12:46:04.492930314Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "class WallFunctionBoundaryTest:\n",
    "    def __init__(self, mask, lattice, flow, wall='bottom', apply_wfb_correction=True,\n",
    "                 smagorinsky_collision_instance=None):\n",
    "        self.mask = lattice.convert_to_tensor(mask)\n",
    "        self.lattice = lattice\n",
    "        self.flow = flow\n",
    "        self.wall = wall\n",
    "        self.apply_wfb_correction = apply_wfb_correction\n",
    "        self.normal_axis = 1\n",
    "\n",
    "        self.tau_x = None\n",
    "        self.tau_z = None\n",
    "        self.u_tau_mean = None\n",
    "        self.y_plus_mean = None\n",
    "        self.Re_tau_mean = None\n",
    "\n",
    "        self.use_smagorinsky = smagorinsky_collision_instance is not None\n",
    "\n",
    "        # Konstruktion der WallQuantitiesInternal – immer\n",
    "        self.wall_quantities_internal = WallQuantitiesInternal(\n",
    "            lattice=self.lattice,\n",
    "            flow=self.flow,\n",
    "            molecular_viscosity=self.flow.units.viscosity_lu,\n",
    "            wall=self.wall,\n",
    "            y_lattice=1.0,\n",
    "            use_smagorinsky=self.use_smagorinsky,\n",
    "            smagorinsky_collision_instance=smagorinsky_collision_instance\n",
    "        )\n",
    "\n",
    "    def set_smagorinsky_collision(self, collision):\n",
    "        self.smagorinsky_collision = collision\n",
    "        self.wall_quantities_internal = WallQuantitiesInternal(\n",
    "            lattice=self.lattice,\n",
    "            flow=self.flow,\n",
    "            molecular_viscosity=self.flow.units.viscosity_lu,\n",
    "            wall=self.wall,\n",
    "            y_lattice=1.0,\n",
    "            smagorinsky_collision_instance=collision\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "    def __call__(self, f):\n",
    "        # --- 1. Klonen der Originalverteilungen für spätere Korrektur ---\n",
    "        if self.wall == 'bottom':\n",
    "            f17_old = f[17, self.mask].clone()\n",
    "            f16_old = f[16, self.mask].clone()\n",
    "            f10_old = f[10, self.mask].clone()\n",
    "            f8_old  = f[8, self.mask].clone()\n",
    "        elif self.wall == 'top':\n",
    "            f15_old = f[15, self.mask].clone()\n",
    "            f18_old = f[18, self.mask].clone()\n",
    "            f7_old  = f[7, self.mask].clone()\n",
    "            f9_old  = f[9, self.mask].clone()\n",
    "        else:\n",
    "            raise ValueError(\"wall must be 'bottom' or 'top'\")\n",
    "\n",
    "        # --- 2. Wall Quantities intern berechnen ---\n",
    "        results = self.wall_quantities_internal(f)\n",
    "        tau_x_field = 0.5 * results[\"tau_x\"]\n",
    "        tau_z_field = 0.5 * results[\"tau_z\"]\n",
    "\n",
    "        # --- 3. Free-Slip Bounce-Back anwenden ---\n",
    "        f = torch.where(self.mask, f[self.lattice.stencil.opposite], f)\n",
    "\n",
    "        # --- 4. Additive Wandkorrektur ---\n",
    "        if self.wall == 'bottom':\n",
    "            f[15, self.mask] = f17_old + tau_z_field[self.mask]\n",
    "            f[16, self.mask] = f17_old + tau_z_field[self.mask]\n",
    "            f[18, self.mask] = f16_old - tau_z_field[self.mask]\n",
    "            f[8,  self.mask] = f16_old - tau_z_field[self.mask]\n",
    "            f[7,  self.mask] = f10_old + tau_x_field[self.mask]\n",
    "            f[17, self.mask] = f10_old + tau_x_field[self.mask]\n",
    "            f[9,  self.mask] = f8_old - tau_x_field[self.mask]\n",
    "            f[10, self.mask] = f8_old - tau_x_field[self.mask]\n",
    "        elif self.wall == 'top':\n",
    "            f[17, self.mask] = f15_old + tau_z_field[self.mask]\n",
    "            f[18, self.mask] = f15_old + tau_z_field[self.mask]\n",
    "            f[16, self.mask] = f18_old - tau_z_field[self.mask]\n",
    "            f[9,  self.mask] = f18_old - tau_z_field[self.mask]\n",
    "            f[10, self.mask] = f7_old + tau_x_field[self.mask]\n",
    "            f[15, self.mask] = f7_old + tau_x_field[self.mask]\n",
    "            f[8,  self.mask] = f9_old - tau_x_field[self.mask]\n",
    "            f[7,  self.mask] = f9_old - tau_x_field[self.mask]\n",
    "\n",
    "        # --- 5. Ergebnisse für Reporter speichern ---\n",
    "        self.tau_x = tau_x_field\n",
    "        self.tau_z = tau_z_field\n",
    "        self.u_tau_mean = results[\"u_tau\"].mean()\n",
    "        self.y_plus_mean = (self.wall_quantities_internal.y * results[\"u_tau\"] / self.wall_quantities_internal.nu).mean()\n",
    "        self.Re_tau_mean = (results[\"u_tau\"] * self.wall_quantities_internal.y / self.wall_quantities_internal.nu).mean()\n",
    "\n",
    "\n",
    "        return f\n",
    "\n",
    "    def make_no_collision_mask(self, f_shape):\n",
    "        \"\"\"\n",
    "        Diese Boundary-Methode liefert die Maske der Wandknoten,\n",
    "        auf denen der Kollisionsschritt der Hauptsimulation übersprungen werden soll.\n",
    "        Diese Klasse operiert auf diesen Wandknoten selbst.\n",
    "        \"\"\"\n",
    "        assert self.mask.shape == f_shape[1:]\n",
    "        # KORREKTUR: Muss die Maske der eigenen Wandknoten (self.mask) zurückgeben.\n",
    "        return self.mask\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-23T12:46:04.522365097Z",
     "start_time": "2025-06-23T12:46:04.500022479Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "class ChannelFlow3DTest(object):\n",
    "    \"\"\"Flow class to simulate the flow around an object (mask) in 3D.\n",
    "    See documentation for :class:`~Obstacle2D` for details.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, resolution_x, resolution_y, resolution_z, reynolds_number, mach_number, lattice, char_length_lu, boundary):\n",
    "        self.resolution_x = resolution_x\n",
    "        self.resolution_y = resolution_y\n",
    "        self.resolution_z = resolution_z\n",
    "\n",
    "        self.units = UnitConversion(\n",
    "            lattice,\n",
    "            reynolds_number=reynolds_number,\n",
    "            mach_number=mach_number,\n",
    "            characteristic_length_lu=char_length_lu,\n",
    "            characteristic_length_pu=1,\n",
    "            characteristic_velocity_pu=1)\n",
    "\n",
    "        self._mask = np.zeros(shape=(self.resolution_x, self.resolution_y, self.resolution_z), dtype=bool)\n",
    "        self._boundary = boundary\n",
    "    @property\n",
    "    def mask(self):\n",
    "        return self._mask\n",
    "\n",
    "    @mask.setter\n",
    "    def mask(self, m):\n",
    "        assert isinstance(m, np.ndarray) and m.shape == (self.resolution_x, self.resolution_y, self.resolution_z)\n",
    "        self._mask = m.astype(bool)\n",
    "\n",
    "    def initial_solution(self, grid):\n",
    "        xg, yg, zg = grid\n",
    "        p = np.ones_like(xg)[None, ...]\n",
    "        nx, ny, nz = self.resolution_x, self.resolution_y, self.resolution_z\n",
    "\n",
    "        u = np.zeros((3, nx, ny, nz))\n",
    "\n",
    "        # --- 📐 Poiseuille-Profil (in x-Richtung) ---\n",
    "        y_normalized = yg / yg.max()\n",
    "        u_base = y_normalized * (1 - y_normalized)\n",
    "        u[0] = u_base * (1 - self.mask.astype(float))  # u_x = Basisströmung\n",
    "\n",
    "        # --- 🎛️ Sinusmoden-Störung (3D) ---\n",
    "        A_sin = 0.5  # 5% Amplitude\n",
    "        Lx, Ly, Lz = xg.max(), yg.max(), zg.max()\n",
    "        sinus_modes = [(1, 1, 1), (2, 2, 3), (3, 2, 1)]\n",
    "\n",
    "        for kx, ky, kz in sinus_modes:\n",
    "            phase = 2 * np.pi * np.random.rand()\n",
    "            mode = np.sin(2 * np.pi * (kx * xg / Lx + ky * yg / Ly + kz * zg / Lz) + phase)\n",
    "            envelope = y_normalized * (1 - y_normalized)\n",
    "            u[0] += A_sin * mode * envelope  # nur u_x gestört, kannst du erweitern\n",
    "\n",
    "        # --- 🌪️ Vektorpotential ψ (3 Komponenten für Curl in 3D) ---\n",
    "        A_psi = 1\n",
    "        random_psi = ((np.random.rand(3, nx, ny, nz) - 0.5) * 2)\n",
    "\n",
    "        # Wandgewichtung in y und z\n",
    "        y_weight = np.exp(-((y_normalized - 0.0) / 0.2) ** 2) + np.exp(-((y_normalized - 1.0) / 0.2) ** 2)\n",
    "        y_weight /= y_weight.max()\n",
    "\n",
    "        z_normalized = zg / zg.max()\n",
    "        z_weight = np.exp(-((z_normalized - 0.5) / 0.3) ** 2)\n",
    "        z_weight /= z_weight.max()\n",
    "\n",
    "        weight = y_weight * z_weight\n",
    "        random_psi *= weight[None, :, :, :]\n",
    "\n",
    "        # FFT-Filterung (3D)\n",
    "        k0 = np.sqrt(nx ** 2 + ny ** 2 + nz ** 2)\n",
    "        psi_filtered = np.empty_like(random_psi)\n",
    "        for d in range(3):\n",
    "            psi_hat = np.fft.fftn(random_psi[d])\n",
    "            kx = np.fft.fftfreq(nx).reshape(-1, 1, 1)\n",
    "            ky = np.fft.fftfreq(ny).reshape(1, -1, 1)\n",
    "            kz = np.fft.fftfreq(nz).reshape(1, 1, -1)\n",
    "            kabs = np.sqrt((kx * nx) ** 2 + (ky * ny) ** 2 + (kz * nz) ** 2)\n",
    "            filter_mask = np.exp(-kabs / (0.3 * k0))\n",
    "            psi_hat *= filter_mask\n",
    "            psi_hat[0, 0, 0] = 0\n",
    "            psi_filtered[d] = np.real(np.fft.ifftn(psi_hat))\n",
    "\n",
    "        # --- 🌀 Curl(ψ): u = ∇ × ψ ---\n",
    "        u_psi = np.zeros_like(u)\n",
    "        u_psi[0] = np.gradient(psi_filtered[2], axis=1) - np.gradient(psi_filtered[1], axis=2)  # u_x\n",
    "        u_psi[1] = np.gradient(psi_filtered[0], axis=2) - np.gradient(psi_filtered[2], axis=0)  # u_y\n",
    "        u_psi[2] = np.gradient(psi_filtered[1], axis=0) - np.gradient(psi_filtered[0], axis=1)  # u_z\n",
    "\n",
    "        # Normierung\n",
    "        umax_psi = np.max(np.sqrt(np.sum(u_psi ** 2, axis=0)))\n",
    "        if umax_psi > 0:\n",
    "            u_psi *= A_psi / umax_psi\n",
    "\n",
    "        # --- Überlagerung: Basis + Sine + Curl ---\n",
    "        u += u_psi\n",
    "        # 2D: Nullsetzen der Wandgeschwindigkeit\n",
    "\n",
    "        u[:, :, 0, :] = 0.0  # untere Wand (y=0)\n",
    "        u[:, :, -1, :] = 0.0  # obere Wand (y=Ny-1)\n",
    "\n",
    "        return p, u\n",
    "\n",
    "    @property\n",
    "    def grid(self):\n",
    "        stop_x = self.resolution_x / self.units.characteristic_length_lu\n",
    "        stop_y = self.resolution_y / self.units.characteristic_length_lu\n",
    "        stop_z = self.resolution_z / self.units.characteristic_length_lu\n",
    "\n",
    "        x = np.linspace(0, stop_x, num=self.resolution_x, endpoint=False)\n",
    "        y = np.linspace(0, stop_y, num=self.resolution_y, endpoint=False)\n",
    "        z = np.linspace(0, stop_z, num=self.resolution_z, endpoint=False)\n",
    "\n",
    "        return np.meshgrid(x, y, z, indexing='ij')\n",
    "\n",
    "    @property\n",
    "    def boundaries(self):\n",
    "        x, y, z = self.grid  # Jetzt auch z\n",
    "        Ny = y.shape[1]  # Höhe des Kanals in y-Richtung\n",
    "\n",
    "        # Bounce-Back-Maske (Wände bei y=0 und y=Ny-1)\n",
    "        # In 3D müssen wir die Maske über alle x- und z-Koordinaten ausdehnen.\n",
    "        mask_bb = np.zeros_like(x, dtype=bool)\n",
    "        mask_bb[:, 0, :] = True  # untere Wand (y=0)\n",
    "        mask_bb[:, Ny - 1, :] = True  # obere Wand (y=Ny-1)\n",
    "\n",
    "        # Wall-Function-Masken (erste Fluidzellen direkt an der Wand)\n",
    "        # Auch hier über alle x- und z-Koordinaten ausdehnen.\n",
    "        mask_bottom = np.zeros_like(x, dtype=bool)\n",
    "        mask_bottom[:, 0, :] = True  # Erste Fluidzelle über der unteren Wand (y=1)\n",
    "\n",
    "        mask_top = np.zeros_like(x, dtype=bool)\n",
    "        mask_top[:, Ny - 1, :] = True  # Erste Fluidzelle unter der oberen Wand (y=Ny-2)\n",
    "\n",
    "        # Das Boundary-Objekt für Bounce-Back\n",
    "\n",
    "        if self._boundary == \"wallfunction\":\n",
    "            bb = [\n",
    "    WallFunctionBoundaryTest(mask_bottom, self.units.lattice, self, wall='bottom'),\n",
    "    WallFunctionBoundaryTest(mask_top,    self.units.lattice, self, wall='top')\n",
    "]\n",
    "\n",
    "        return bb\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-23T12:46:04.525099263Z",
     "start_time": "2025-06-23T12:46:04.521467711Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "class WallQuantitiesTest:\n",
    "    def __init__(self, lattice, flow, boundary):\n",
    "        self.lattice = lattice\n",
    "        self.flow = flow\n",
    "        self.boundary = boundary\n",
    "\n",
    "    def __call__(self, f):\n",
    "        if not hasattr(self.boundary, \"wall_quantities_internal\"):\n",
    "            print(\"⚠️ `wall_quantities_internal` noch nicht gesetzt – WallQuantitiesTest überspringt Schritt.\")\n",
    "            return torch.zeros(5)\n",
    "\n",
    "        result = self.boundary.wall_quantities_internal(f)\n",
    "        u_tau = result[\"u_tau\"]\n",
    "        y = self.boundary.wall_quantities_internal.y\n",
    "        nu = self.boundary.wall_quantities_internal.nu\n",
    "        print(\"Re_Tau=\" + str(torch.mean(y * u_tau / nu)))\n",
    "        print(\"y+=\" + str(torch.mean(u_tau * y / nu)))\n",
    "        return torch.tensor([\n",
    "            result[\"tau_x\"].mean(),\n",
    "            result[\"tau_z\"].mean(),\n",
    "            u_tau.mean(),\n",
    "            (y * u_tau / nu).mean(),\n",
    "            (u_tau * y / nu).mean()\n",
    "        ])\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-23T12:46:04.572974674Z",
     "start_time": "2025-06-23T12:46:04.525510671Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ICH FUNKTIONIERE MIT PULLEN\n"
     ]
    }
   ],
   "source": [
    "from argparse import ArgumentParser, ArgumentDefaultsHelpFormatter\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "parser = ArgumentParser(formatter_class=ArgumentDefaultsHelpFormatter)\n",
    "parser.add_argument(\"--vtkdir\", type=str, default=\"./output/\")\n",
    "parser.add_argument(\"--csvdir\", type=str, default=\"./output/\")\n",
    "parser.add_argument(\"--nout\", type=int, default=100)\n",
    "parser.add_argument(\"--nvtk\", type=int, default=100)\n",
    "parser.add_argument(\"--tmax\", type=int, default=0.1)\n",
    "parser.add_argument(\"--Re\", type=int, default=13800)\n",
    "parser.add_argument(\"--collision_operator\", type=str, default=\"Smag\")\n",
    "parser.add_argument(\"--Precision\", type=str, default=\"Double\")\n",
    "parser.add_argument(\"--Mach\", type=float, default=0.1)\n",
    "parser.add_argument(\"--h\", type=int, default=20, help=\"Halbe Kanalhöhe in LU\")\n",
    "parser.add_argument(\"--bbtype\", type=str, default=\"wallfunction\", choices=[\"halfway\", \"fullway\", \"wallfunction\", \"freeslip\"],\n",
    "                    help=\"Typ der Bounce-Back-Randbedingung\")\n",
    "\n",
    "args, unknown = parser.parse_known_args()\n",
    "args = vars(args)\n",
    "\n",
    "print(\"ICH FUNKTIONIERE MIT PULLEN\")\n",
    "\n",
    "\n",
    "\n",
    "# Einheiten und Auflösung\n",
    "h = args[\"h\"]                      # Kanalhalbhöhe in LU\n",
    "res_y = 2 * h                     # y: volle Kanalhöhe\n",
    "res_x = int(2*np.pi * h)\n",
    "res_z = int(np.pi * h)\n",
    "\n",
    "# Restliche Parameter\n",
    "Re = args[\"Re\"]\n",
    "basedir = args[\"vtkdir\"]\n",
    "csvdir = args[\"csvdir\"]\n",
    "nout = args[\"nout\"]\n",
    "nvtk = args[\"nvtk\"]\n",
    "tmax = args[\"tmax\"]\n",
    "Precision = args[\"Precision\"]\n",
    "collision_operator = args[\"collision_operator\"]\n",
    "Mach = args[\"Mach\"]\n",
    "bbtype = args[\"bbtype\"]\n",
    "# Präzision\n",
    "if Precision == \"Single\":\n",
    "    dtype = torch.float32\n",
    "elif Precision == \"Double\":\n",
    "    dtype = torch.float64\n",
    "elif Precision == \"Half\":\n",
    "    dtype = torch.float16\n",
    "\n",
    "\n",
    "Re_tau = 180\n",
    "\n",
    "smagorinsky_constant = 0.17\n",
    "\n",
    "delta_x = 1.0"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-23T12:46:04.573529249Z",
     "start_time": "2025-06-23T12:46:04.568670315Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA ist nicht verfügbar. Verwende CPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ben/anaconda3/envs/lettuce/lib/python3.11/site-packages/torch/cuda/__init__.py:138: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at /opt/conda/conda-bld/pytorch_1695392035891/work/c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steps     time     GlobalMeanUXReporter\n",
      "steps     time     WallQuantitiesTest\n",
      "steps     time     WallQuantitiesTest\n",
      "steps     time     IncompressibleKineticEnergy\n",
      "Starte Simulation für 69 Schritte auf cpu...\n",
      "Re_Tau=tensor(6.1804, dtype=torch.float64)\n",
      "y+=tensor(6.1804, dtype=torch.float64)\n",
      "Re_Tau=tensor(6.1518, dtype=torch.float64)\n",
      "y+=tensor(6.1518, dtype=torch.float64)\n",
      "⚠️ u_tau_mean nicht verfügbar. AdaptiveForce überspringt Kraftberechnung.\n",
      "Re_Tau=tensor(4.9414, dtype=torch.float64)\n",
      "y+=tensor(4.9414, dtype=torch.float64)\n",
      "Re_Tau=tensor(4.9294, dtype=torch.float64)\n",
      "y+=tensor(4.9294, dtype=torch.float64)\n",
      "⚠️ u_tau_mean nicht verfügbar. AdaptiveForce überspringt Kraftberechnung.\n",
      "Re_Tau=tensor(4.7386, dtype=torch.float64)\n",
      "y+=tensor(4.7386, dtype=torch.float64)\n",
      "Re_Tau=tensor(4.7584, dtype=torch.float64)\n",
      "y+=tensor(4.7584, dtype=torch.float64)\n",
      "⚠️ u_tau_mean nicht verfügbar. AdaptiveForce überspringt Kraftberechnung.\n",
      "Re_Tau=tensor(4.8746, dtype=torch.float64)\n",
      "y+=tensor(4.8746, dtype=torch.float64)\n",
      "Re_Tau=tensor(4.8806, dtype=torch.float64)\n",
      "y+=tensor(4.8806, dtype=torch.float64)\n",
      "⚠️ u_tau_mean nicht verfügbar. AdaptiveForce überspringt Kraftberechnung.\n",
      "Re_Tau=tensor(5.0086, dtype=torch.float64)\n",
      "y+=tensor(5.0086, dtype=torch.float64)\n",
      "Re_Tau=tensor(5.0505, dtype=torch.float64)\n",
      "y+=tensor(5.0505, dtype=torch.float64)\n",
      "⚠️ u_tau_mean nicht verfügbar. AdaptiveForce überspringt Kraftberechnung.\n",
      "Re_Tau=tensor(4.9742, dtype=torch.float64)\n",
      "y+=tensor(4.9742, dtype=torch.float64)\n",
      "Re_Tau=tensor(5.0163, dtype=torch.float64)\n",
      "y+=tensor(5.0163, dtype=torch.float64)\n",
      "⚠️ u_tau_mean nicht verfügbar. AdaptiveForce überspringt Kraftberechnung.\n",
      "Re_Tau=tensor(5.0787, dtype=torch.float64)\n",
      "y+=tensor(5.0787, dtype=torch.float64)\n",
      "Re_Tau=tensor(5.0682, dtype=torch.float64)\n",
      "y+=tensor(5.0682, dtype=torch.float64)\n",
      "⚠️ u_tau_mean nicht verfügbar. AdaptiveForce überspringt Kraftberechnung.\n",
      "Re_Tau=tensor(4.8929, dtype=torch.float64)\n",
      "y+=tensor(4.8929, dtype=torch.float64)\n",
      "Re_Tau=tensor(4.8816, dtype=torch.float64)\n",
      "y+=tensor(4.8816, dtype=torch.float64)\n",
      "⚠️ u_tau_mean nicht verfügbar. AdaptiveForce überspringt Kraftberechnung.\n",
      "Re_Tau=tensor(5.0228, dtype=torch.float64)\n",
      "y+=tensor(5.0228, dtype=torch.float64)\n",
      "Re_Tau=tensor(5.0272, dtype=torch.float64)\n",
      "y+=tensor(5.0272, dtype=torch.float64)\n",
      "⚠️ u_tau_mean nicht verfügbar. AdaptiveForce überspringt Kraftberechnung.\n",
      "Re_Tau=tensor(4.9104, dtype=torch.float64)\n",
      "y+=tensor(4.9104, dtype=torch.float64)\n",
      "Re_Tau=tensor(4.9149, dtype=torch.float64)\n",
      "y+=tensor(4.9149, dtype=torch.float64)\n",
      "⚠️ u_tau_mean nicht verfügbar. AdaptiveForce überspringt Kraftberechnung.\n",
      "Re_Tau=tensor(5.0002, dtype=torch.float64)\n",
      "y+=tensor(5.0002, dtype=torch.float64)\n",
      "Re_Tau=tensor(5.0221, dtype=torch.float64)\n",
      "y+=tensor(5.0221, dtype=torch.float64)\n",
      "⚠️ u_tau_mean nicht verfügbar. AdaptiveForce überspringt Kraftberechnung.\n",
      "Re_Tau=tensor(4.9201, dtype=torch.float64)\n",
      "y+=tensor(4.9201, dtype=torch.float64)\n",
      "Re_Tau=tensor(4.9163, dtype=torch.float64)\n",
      "y+=tensor(4.9163, dtype=torch.float64)\n",
      "⚠️ u_tau_mean nicht verfügbar. AdaptiveForce überspringt Kraftberechnung.\n",
      "Re_Tau=tensor(5.1184, dtype=torch.float64)\n",
      "y+=tensor(5.1184, dtype=torch.float64)\n",
      "Re_Tau=tensor(5.1255, dtype=torch.float64)\n",
      "y+=tensor(5.1255, dtype=torch.float64)\n",
      "⚠️ u_tau_mean nicht verfügbar. AdaptiveForce überspringt Kraftberechnung.\n",
      "Re_Tau=tensor(4.9665, dtype=torch.float64)\n",
      "y+=tensor(4.9665, dtype=torch.float64)\n",
      "Re_Tau=tensor(4.9761, dtype=torch.float64)\n",
      "y+=tensor(4.9761, dtype=torch.float64)\n",
      "⚠️ u_tau_mean nicht verfügbar. AdaptiveForce überspringt Kraftberechnung.\n",
      "Re_Tau=tensor(5.0544, dtype=torch.float64)\n",
      "y+=tensor(5.0544, dtype=torch.float64)\n",
      "Re_Tau=tensor(5.0678, dtype=torch.float64)\n",
      "y+=tensor(5.0678, dtype=torch.float64)\n",
      "⚠️ u_tau_mean nicht verfügbar. AdaptiveForce überspringt Kraftberechnung.\n",
      "Re_Tau=tensor(4.9741, dtype=torch.float64)\n",
      "y+=tensor(4.9741, dtype=torch.float64)\n",
      "Re_Tau=tensor(4.9672, dtype=torch.float64)\n",
      "y+=tensor(4.9672, dtype=torch.float64)\n",
      "⚠️ u_tau_mean nicht verfügbar. AdaptiveForce überspringt Kraftberechnung.\n",
      "Re_Tau=tensor(5.1737, dtype=torch.float64)\n",
      "y+=tensor(5.1737, dtype=torch.float64)\n",
      "Re_Tau=tensor(5.1796, dtype=torch.float64)\n",
      "y+=tensor(5.1796, dtype=torch.float64)\n",
      "⚠️ u_tau_mean nicht verfügbar. AdaptiveForce überspringt Kraftberechnung.\n",
      "Re_Tau=tensor(5.0357, dtype=torch.float64)\n",
      "y+=tensor(5.0357, dtype=torch.float64)\n",
      "Re_Tau=tensor(5.0649, dtype=torch.float64)\n",
      "y+=tensor(5.0649, dtype=torch.float64)\n",
      "⚠️ u_tau_mean nicht verfügbar. AdaptiveForce überspringt Kraftberechnung.\n",
      "Re_Tau=tensor(5.2255, dtype=torch.float64)\n",
      "y+=tensor(5.2255, dtype=torch.float64)\n",
      "Re_Tau=tensor(5.2306, dtype=torch.float64)\n",
      "y+=tensor(5.2306, dtype=torch.float64)\n",
      "⚠️ u_tau_mean nicht verfügbar. AdaptiveForce überspringt Kraftberechnung.\n",
      "Re_Tau=tensor(5.0426, dtype=torch.float64)\n",
      "y+=tensor(5.0426, dtype=torch.float64)\n",
      "Re_Tau=tensor(5.0276, dtype=torch.float64)\n",
      "y+=tensor(5.0276, dtype=torch.float64)\n",
      "⚠️ u_tau_mean nicht verfügbar. AdaptiveForce überspringt Kraftberechnung.\n",
      "Re_Tau=tensor(5.2142, dtype=torch.float64)\n",
      "y+=tensor(5.2142, dtype=torch.float64)\n",
      "Re_Tau=tensor(5.2057, dtype=torch.float64)\n",
      "y+=tensor(5.2057, dtype=torch.float64)\n",
      "⚠️ u_tau_mean nicht verfügbar. AdaptiveForce überspringt Kraftberechnung.\n",
      "Re_Tau=tensor(5.1325, dtype=torch.float64)\n",
      "y+=tensor(5.1325, dtype=torch.float64)\n",
      "Re_Tau=tensor(5.1265, dtype=torch.float64)\n",
      "y+=tensor(5.1265, dtype=torch.float64)\n",
      "⚠️ u_tau_mean nicht verfügbar. AdaptiveForce überspringt Kraftberechnung.\n",
      "Re_Tau=tensor(5.2513, dtype=torch.float64)\n",
      "y+=tensor(5.2513, dtype=torch.float64)\n",
      "Re_Tau=tensor(5.2519, dtype=torch.float64)\n",
      "y+=tensor(5.2519, dtype=torch.float64)\n",
      "⚠️ u_tau_mean nicht verfügbar. AdaptiveForce überspringt Kraftberechnung.\n",
      "Re_Tau=tensor(5.1493, dtype=torch.float64)\n",
      "y+=tensor(5.1493, dtype=torch.float64)\n",
      "Re_Tau=tensor(5.1304, dtype=torch.float64)\n",
      "y+=tensor(5.1304, dtype=torch.float64)\n",
      "⚠️ u_tau_mean nicht verfügbar. AdaptiveForce überspringt Kraftberechnung.\n",
      "Re_Tau=tensor(5.3133, dtype=torch.float64)\n",
      "y+=tensor(5.3133, dtype=torch.float64)\n",
      "Re_Tau=tensor(5.3075, dtype=torch.float64)\n",
      "y+=tensor(5.3075, dtype=torch.float64)\n",
      "⚠️ u_tau_mean nicht verfügbar. AdaptiveForce überspringt Kraftberechnung.\n",
      "Re_Tau=tensor(5.1792, dtype=torch.float64)\n",
      "y+=tensor(5.1792, dtype=torch.float64)\n",
      "Re_Tau=tensor(5.1547, dtype=torch.float64)\n",
      "y+=tensor(5.1547, dtype=torch.float64)\n",
      "⚠️ u_tau_mean nicht verfügbar. AdaptiveForce überspringt Kraftberechnung.\n",
      "Re_Tau=tensor(5.3022, dtype=torch.float64)\n",
      "y+=tensor(5.3022, dtype=torch.float64)\n",
      "Re_Tau=tensor(5.2799, dtype=torch.float64)\n",
      "y+=tensor(5.2799, dtype=torch.float64)\n",
      "⚠️ u_tau_mean nicht verfügbar. AdaptiveForce überspringt Kraftberechnung.\n",
      "Re_Tau=tensor(5.1772, dtype=torch.float64)\n",
      "y+=tensor(5.1772, dtype=torch.float64)\n",
      "Re_Tau=tensor(5.1403, dtype=torch.float64)\n",
      "y+=tensor(5.1403, dtype=torch.float64)\n",
      "⚠️ u_tau_mean nicht verfügbar. AdaptiveForce überspringt Kraftberechnung.\n",
      "Re_Tau=tensor(5.3054, dtype=torch.float64)\n",
      "y+=tensor(5.3054, dtype=torch.float64)\n",
      "Re_Tau=tensor(5.2882, dtype=torch.float64)\n",
      "y+=tensor(5.2882, dtype=torch.float64)\n",
      "⚠️ u_tau_mean nicht verfügbar. AdaptiveForce überspringt Kraftberechnung.\n",
      "Re_Tau=tensor(5.1825, dtype=torch.float64)\n",
      "y+=tensor(5.1825, dtype=torch.float64)\n",
      "Re_Tau=tensor(5.1633, dtype=torch.float64)\n",
      "y+=tensor(5.1633, dtype=torch.float64)\n",
      "⚠️ u_tau_mean nicht verfügbar. AdaptiveForce überspringt Kraftberechnung.\n",
      "Re_Tau=tensor(5.3037, dtype=torch.float64)\n",
      "y+=tensor(5.3037, dtype=torch.float64)\n",
      "Re_Tau=tensor(5.2814, dtype=torch.float64)\n",
      "y+=tensor(5.2814, dtype=torch.float64)\n",
      "⚠️ u_tau_mean nicht verfügbar. AdaptiveForce überspringt Kraftberechnung.\n",
      "Re_Tau=tensor(5.1601, dtype=torch.float64)\n",
      "y+=tensor(5.1601, dtype=torch.float64)\n",
      "Re_Tau=tensor(5.1178, dtype=torch.float64)\n",
      "y+=tensor(5.1178, dtype=torch.float64)\n",
      "⚠️ u_tau_mean nicht verfügbar. AdaptiveForce überspringt Kraftberechnung.\n",
      "Re_Tau=tensor(5.2695, dtype=torch.float64)\n",
      "y+=tensor(5.2695, dtype=torch.float64)\n",
      "Re_Tau=tensor(5.2366, dtype=torch.float64)\n",
      "y+=tensor(5.2366, dtype=torch.float64)\n",
      "⚠️ u_tau_mean nicht verfügbar. AdaptiveForce überspringt Kraftberechnung.\n",
      "Re_Tau=tensor(5.1323, dtype=torch.float64)\n",
      "y+=tensor(5.1323, dtype=torch.float64)\n",
      "Re_Tau=tensor(5.0851, dtype=torch.float64)\n",
      "y+=tensor(5.0851, dtype=torch.float64)\n",
      "⚠️ u_tau_mean nicht verfügbar. AdaptiveForce überspringt Kraftberechnung.\n",
      "Re_Tau=tensor(5.2555, dtype=torch.float64)\n",
      "y+=tensor(5.2555, dtype=torch.float64)\n",
      "Re_Tau=tensor(5.2296, dtype=torch.float64)\n",
      "y+=tensor(5.2296, dtype=torch.float64)\n",
      "⚠️ u_tau_mean nicht verfügbar. AdaptiveForce überspringt Kraftberechnung.\n",
      "Re_Tau=tensor(5.0929, dtype=torch.float64)\n",
      "y+=tensor(5.0929, dtype=torch.float64)\n",
      "Re_Tau=tensor(5.0621, dtype=torch.float64)\n",
      "y+=tensor(5.0621, dtype=torch.float64)\n",
      "⚠️ u_tau_mean nicht verfügbar. AdaptiveForce überspringt Kraftberechnung.\n",
      "Re_Tau=tensor(5.2354, dtype=torch.float64)\n",
      "y+=tensor(5.2354, dtype=torch.float64)\n",
      "Re_Tau=tensor(5.2201, dtype=torch.float64)\n",
      "y+=tensor(5.2201, dtype=torch.float64)\n",
      "⚠️ u_tau_mean nicht verfügbar. AdaptiveForce überspringt Kraftberechnung.\n",
      "Re_Tau=tensor(5.0918, dtype=torch.float64)\n",
      "y+=tensor(5.0918, dtype=torch.float64)\n",
      "Re_Tau=tensor(5.0661, dtype=torch.float64)\n",
      "y+=tensor(5.0661, dtype=torch.float64)\n",
      "⚠️ u_tau_mean nicht verfügbar. AdaptiveForce überspringt Kraftberechnung.\n",
      "Re_Tau=tensor(5.2292, dtype=torch.float64)\n",
      "y+=tensor(5.2292, dtype=torch.float64)\n",
      "Re_Tau=tensor(5.2123, dtype=torch.float64)\n",
      "y+=tensor(5.2123, dtype=torch.float64)\n",
      "⚠️ u_tau_mean nicht verfügbar. AdaptiveForce überspringt Kraftberechnung.\n",
      "Re_Tau=tensor(5.1206, dtype=torch.float64)\n",
      "y+=tensor(5.1206, dtype=torch.float64)\n",
      "Re_Tau=tensor(5.0962, dtype=torch.float64)\n",
      "y+=tensor(5.0962, dtype=torch.float64)\n",
      "⚠️ u_tau_mean nicht verfügbar. AdaptiveForce überspringt Kraftberechnung.\n",
      "Re_Tau=tensor(5.2366, dtype=torch.float64)\n",
      "y+=tensor(5.2366, dtype=torch.float64)\n",
      "Re_Tau=tensor(5.2313, dtype=torch.float64)\n",
      "y+=tensor(5.2313, dtype=torch.float64)\n",
      "⚠️ u_tau_mean nicht verfügbar. AdaptiveForce überspringt Kraftberechnung.\n",
      "Re_Tau=tensor(5.1118, dtype=torch.float64)\n",
      "y+=tensor(5.1118, dtype=torch.float64)\n",
      "Re_Tau=tensor(5.0995, dtype=torch.float64)\n",
      "y+=tensor(5.0995, dtype=torch.float64)\n",
      "⚠️ u_tau_mean nicht verfügbar. AdaptiveForce überspringt Kraftberechnung.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[7], line 117\u001B[0m\n\u001B[1;32m    113\u001B[0m wfb_top(simulation\u001B[38;5;241m.\u001B[39mf)\n\u001B[1;32m    116\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mStarte Simulation für \u001B[39m\u001B[38;5;132;01m{\u001B[39;00msteps\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m Schritte auf \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mdevice\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m...\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m--> 117\u001B[0m mlups \u001B[38;5;241m=\u001B[39m \u001B[43msimulation\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstep\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnum_steps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msteps\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    118\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSimulation beendet. MLUPS: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmlups\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    119\u001B[0m wq_top \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39marray(simulation\u001B[38;5;241m.\u001B[39mreporters[\u001B[38;5;241m2\u001B[39m]\u001B[38;5;241m.\u001B[39mout)\n",
      "File \u001B[0;32m~/lettuce/lettuce/simulation.py:84\u001B[0m, in \u001B[0;36mSimulation.step\u001B[0;34m(self, num_steps)\u001B[0m\n\u001B[1;32m     81\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mf \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mwhere(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mno_collision_mask, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mf, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcollision(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mf))\n\u001B[1;32m     83\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m boundary \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_boundaries:\n\u001B[0;32m---> 84\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mf \u001B[38;5;241m=\u001B[39m \u001B[43mboundary\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mf\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     86\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_report()\n\u001B[1;32m     90\u001B[0m end \u001B[38;5;241m=\u001B[39m timer()\n",
      "Cell \u001B[0;32mIn[3], line 59\u001B[0m, in \u001B[0;36mWallFunctionBoundaryTest.__call__\u001B[0;34m(self, f)\u001B[0m\n\u001B[1;32m     56\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mwall must be \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbottom\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m or \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtop\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     58\u001B[0m \u001B[38;5;66;03m# --- 2. Wall Quantities intern berechnen ---\u001B[39;00m\n\u001B[0;32m---> 59\u001B[0m results \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwall_quantities_internal\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     60\u001B[0m tau_x_field \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0.5\u001B[39m \u001B[38;5;241m*\u001B[39m results[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtau_x\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[1;32m     61\u001B[0m tau_z_field \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0.5\u001B[39m \u001B[38;5;241m*\u001B[39m results[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtau_z\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
      "Cell \u001B[0;32mIn[2], line 90\u001B[0m, in \u001B[0;36mWallQuantitiesInternal.__call__\u001B[0;34m(self, f_full_grid)\u001B[0m\n\u001B[1;32m     87\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     88\u001B[0m     nu_eff_wall_layer \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mfull_like(u_mag_wall_parallel, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnu)\n\u001B[0;32m---> 90\u001B[0m u_plus \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mspalding_law\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mu_mag_wall_parallel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnu_eff_wall_layer\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     91\u001B[0m u_tau \u001B[38;5;241m=\u001B[39m (u_mag_wall_parallel \u001B[38;5;241m/\u001B[39m u_plus)\u001B[38;5;241m.\u001B[39mclamp(\u001B[38;5;28mmin\u001B[39m\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1e-8\u001B[39m)\n\u001B[1;32m     92\u001B[0m tau_w \u001B[38;5;241m=\u001B[39m rho_f \u001B[38;5;241m*\u001B[39m u_tau\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m2\u001B[39m\n",
      "Cell \u001B[0;32mIn[2], line 55\u001B[0m, in \u001B[0;36mWallQuantitiesInternal.spalding_law\u001B[0;34m(self, y_plus_grid_dist, u_mag_wall_parallel, nu_effective)\u001B[0m\n\u001B[1;32m     52\u001B[0m df_eq_solve \u001B[38;5;241m=\u001B[39m d_spalding_term \u001B[38;5;241m-\u001B[39m d_rhs\n\u001B[1;32m     54\u001B[0m delta \u001B[38;5;241m=\u001B[39m f_eq_solve \u001B[38;5;241m/\u001B[39m torch\u001B[38;5;241m.\u001B[39mwhere(torch\u001B[38;5;241m.\u001B[39mabs(df_eq_solve) \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m1e-10\u001B[39m, torch\u001B[38;5;241m.\u001B[39mtensor(\u001B[38;5;241m1e-10\u001B[39m, device\u001B[38;5;241m=\u001B[39mf_eq_solve\u001B[38;5;241m.\u001B[39mdevice), df_eq_solve)\n\u001B[0;32m---> 55\u001B[0m u_plus \u001B[38;5;241m=\u001B[39m \u001B[43m(\u001B[49m\u001B[43mu_plus\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mdelta\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mclamp\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mmin\u001B[39;49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1e-4\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m     57\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mmax(torch\u001B[38;5;241m.\u001B[39mabs(delta)) \u001B[38;5;241m<\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtol:\n\u001B[1;32m     58\u001B[0m     \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "    print(\"CUDA ist verfügbar. Verwende GPU.\")\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "    print(\"CUDA ist nicht verfügbar. Verwende CPU.\")\n",
    "\n",
    "dtype = torch.float64 # Für Stabilität bei hohen Re\n",
    "\n",
    "# --- 🧱 Lattice & Flow Initialisierung ---\n",
    "# D3Q19() muss instanziiert werden. Lattice bekommt die Instanz.\n",
    "lattice = Lattice(D3Q19(), device=device, dtype=dtype)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "flow = ChannelFlow3DTest(\n",
    "    resolution_x=res_x,\n",
    "    resolution_y=res_y,\n",
    "    resolution_z=res_z,\n",
    "    reynolds_number=Re, # Re_bulk\n",
    "    mach_number=Mach, # Physikalische Mach-Zahl\n",
    "    lattice=lattice,\n",
    "    char_length_lu=res_y, # Charakteristische Länge in LU ist gesamte Höhe 2H\n",
    "    boundary=bbtype # Signalisiert dem flow.boundaries, welche Boundary-Art erstellt wird\n",
    ")\n",
    "\n",
    "# --- NEUE KOMPONENTEN FÜR ADAPTIVES FORCING ---\n",
    "\n",
    "# 1. Reporter, die die benötigten Mittelwerte liefern\n",
    "# Diese Reporter müssen die Werte als zugängliche Attribute speichern (z.B. self.last_u_tau_spatial_mean)\n",
    "# Stellen Sie sicher, dass Ihre WallQuantities.__call__ diese Attribute setzt.\n",
    "# Beispiel für WallQuantities.__call__ Erweiterung:\n",
    "# class WallQuantities(...):\n",
    "#     # ...\n",
    "#     def __call__(self, f):\n",
    "#         # ... (alle Berechnungen von u_tau_current) ...\n",
    "#         self.last_u_tau_spatial_mean = torch.mean(u_tau_current).item() # HIER HINZUFÜGEN\n",
    "#         # ... return torch.zeros(4,...)\n",
    "\n",
    "# Globaler Reporter für mittlere U_x über die Domäne\n",
    "global_mean_ux_reporter = GlobalMeanUXReporter(lattice, flow)\n",
    "\n",
    "wfb_bottom = flow.boundaries[0]\n",
    "wfb_top = flow.boundaries[1]\n",
    "\n",
    "# Reporter, die nur \"lesen\"\n",
    "wq_bottom = WallQuantitiesTest( lattice=lattice, flow=flow, boundary=wfb_bottom)\n",
    "wq_top = WallQuantitiesTest( lattice=lattice, flow=flow, boundary=wfb_top)\n",
    "\n",
    "\n",
    "# 2. AdaptiveForce Klasse initialisieren\n",
    "# Sie braucht die Reporter, um die Werte zu bekommen.\n",
    "# target_u_m_pu kommt aus Paper Tabelle 2: 1.0 m/s\n",
    "adaptive_force_instance = AdaptiveForce(\n",
    "    lattice=lattice,\n",
    "    flow=flow,\n",
    "    target_u_m_lu=flow.units.convert_velocity_to_lu(1.0),\n",
    "    wall_bottom=wfb_bottom,\n",
    "    wall_top=wfb_top,\n",
    "    global_ux_reporter=global_mean_ux_reporter,\n",
    "    base_lbm_tau_lu = flow.units.relaxation_parameter_lu\n",
    ")\n",
    "# --- 3. Kollisionsmodell mit dem adaptiven Forcing initialisieren ---\n",
    "# Der 'force'-Parameter der SmagorinskyCollision erwartet ein Force-Objekt.\n",
    "collision = lettuce.SmagorinskyCollision(lattice, tau=flow.units.relaxation_parameter_lu, force=adaptive_force_instance)\n",
    "\n",
    "# flow schon initialisiert\n",
    "wfb_bottom = flow.boundaries[0]\n",
    "wfb_top = flow.boundaries[1]\n",
    "\n",
    "# Jetzt collision erzeugen\n",
    "\n",
    "# Dann collision in boundaries nachtragen\n",
    "wfb_bottom.set_smagorinsky_collision(collision)\n",
    "wfb_top.set_smagorinsky_collision(collision)\n",
    "\n",
    "# --- Simulation Setup ---\n",
    "streaming = StandardStreaming(lattice)\n",
    "simulation = Simulation(flow=flow, lattice=lattice, collision=collision, streaming=streaming)\n",
    "\n",
    "\n",
    "# --- 📊 Reporter zur Simulation hinzufügen ---\n",
    "# Die Reporter, die als Input für AdaptiveForce dienen, MÜSSEN vor dem AdaptiveForce-Aufruf in der Simulationsschleife aktualisiert werden.\n",
    "# Lettuce ruft die Reporter VOR den Boundaries und der Kollision auf, wenn sie als Simulation-Reporter hinzugefügt werden.\n",
    "# Es ist wichtig, dass GlobalMeanUXReporter und WallQuantities zuerst in der Liste der Reporter stehen,\n",
    "# damit ihre 'last_...' Attribute aktualisiert werden, bevor AdaptiveForce in collision(f) aufgerufen wird.\n",
    "simulation.reporters.append(lt.ObservableReporter(global_mean_ux_reporter, interval=1, out=None))\n",
    "simulation.reporters.append(lt.ObservableReporter(wq_bottom, interval=1, out=None))\n",
    "simulation.reporters.append(lt.ObservableReporter(wq_top, interval=1, out=None))\n",
    "\n",
    "# Andere Reporter\n",
    "# Energy Reporter\n",
    "simulation.reporters.append(lt.ObservableReporter(lt.observables.IncompressibleKineticEnergy(lattice, flow), interval=100, out=None))\n",
    "# VTK Reporter\n",
    "\n",
    "steps = int(flow.units.convert_time_to_lu(tmax))\n",
    "\n",
    "\n",
    "vtk_reporter = lt.VTKReporter(\n",
    "    lattice=lattice, flow=flow, interval=max(1,int(steps/100)), filename_base=basedir + \"/output\"\n",
    ")\n",
    "simulation.reporters.append(vtk_reporter)\n",
    "\n",
    "\n",
    "# --- Simulation starten ---\n",
    "# Die Methode initialize_f_neq sollte nach der Initialisierung von Lattice und Flow aufgerufen werden,\n",
    "# um f mit dem initialen Geschwindigkeits- und Druckfeld zu füllen.\n",
    "simulation.initialize_f_neq() # Initialisiert f in simulation.f\n",
    "\n",
    "# Vor dem ersten Schritt\n",
    "wfb_bottom(simulation.f)\n",
    "wfb_top(simulation.f)\n",
    "\n",
    "\n",
    "print(f\"Starte Simulation für {steps} Schritte auf {device}...\")\n",
    "mlups = simulation.step(num_steps=steps)\n",
    "print(f\"Simulation beendet. MLUPS: {mlups}\")\n",
    "wq_top = np.array(simulation.reporters[2].out)\n",
    "wq_bottom = np.array(simulation.reporters[1].out)\n",
    "ux_mean = np.array(simulation.reporters[0].out)\n",
    "\n",
    "\n",
    "\n",
    "with open(csvdir + 'uxmean.csv', 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerows(ux_mean)\n",
    "with open(csvdir + 'WallQuantitiesTop.csv', 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerows(wq_top)\n",
    "with open(csvdir + 'WallQuantitiesBottom.csv', 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerows(wq_bottom)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-23T12:46:22.884785296Z",
     "start_time": "2025-06-23T12:46:04.568936278Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(ux_mean)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Beispiel: Daten laden\n",
    "data = (wq_bottom+wq_top)/2\n",
    "time = data[:, 1]\n",
    "re_tau = data[:, 5]\n",
    "y_plus = data[:, 6]\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(time, re_tau, label=\"Re_tau (bottom)\")\n",
    "plt.xlabel(\"Zeit\")\n",
    "plt.ylabel(\"Re_tau\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.title(\"Re_tau über die Zeit\")\n",
    "plt.savefig(csvdir + \"retau.pdf\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(time, y_plus, label=\"y⁺ (bottom)\")\n",
    "plt.xlabel(\"Zeit\")\n",
    "plt.ylabel(\"y⁺\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.title(\"y⁺ über die Zeit\")\n",
    "plt.savefig(csvdir + \"yplus.pdf\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(ux_mean[:, 1], flow.units.convert_velocity_to_pu(ux_mean[:, 2]))\n",
    "plt.xlabel(\"Zeit\")\n",
    "plt.ylabel(\"ux_mean\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.title(\"ux_mean\")\n",
    "plt.savefig(csvdir + \"ux.pdf\")\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
