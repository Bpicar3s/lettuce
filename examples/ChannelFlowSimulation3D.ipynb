{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import lettuce as lt\n",
    "from lettuce import D3Q19, Lattice, UnitConversion\n",
    "import csv"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-24T15:47:00.074714508Z",
     "start_time": "2025-06-24T15:46:59.194674183Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "\n",
    "class WallQuantitiesInternal:\n",
    "    def __init__(\n",
    "        self,\n",
    "        lattice,\n",
    "        flow,\n",
    "        molecular_viscosity,\n",
    "        y_lattice=1.0,\n",
    "        wall='bottom',\n",
    "        kappa=0.41,\n",
    "        B=5.2,\n",
    "        max_iter=100,\n",
    "        tol=1e-8,\n",
    "        use_smagorinsky=False,\n",
    "        smagorinsky_collision_instance=None\n",
    "    ):\n",
    "        self.lattice = lattice\n",
    "        self.flow = flow\n",
    "        self.nu = molecular_viscosity\n",
    "        self.y = y_lattice\n",
    "        self.wall = wall\n",
    "        self.kappa = kappa\n",
    "        self.B = B\n",
    "        self.max_iter = max_iter\n",
    "        self.tol = tol\n",
    "        self.normal_axis = 1  # y-Achse\n",
    "\n",
    "        self.use_smagorinsky = use_smagorinsky\n",
    "        if self.use_smagorinsky:\n",
    "            if smagorinsky_collision_instance is None:\n",
    "                raise ValueError(\"Smagorinsky collision instance required if use_smagorinsky=True.\")\n",
    "            self.smagorinsky_collision = smagorinsky_collision_instance\n",
    "\n",
    "    def spalding_law(self, y_plus_grid_dist, u_mag_wall_parallel, nu_effective):\n",
    "        y_plus_grid_dist = torch.tensor(y_plus_grid_dist, device=u_mag_wall_parallel.device, dtype=u_mag_wall_parallel.dtype)\n",
    "        u_plus = (y_plus_grid_dist * u_mag_wall_parallel / nu_effective).clamp(min=1e-4).detach().clone().requires_grad_(False)\n",
    "\n",
    "        for _ in range(self.max_iter):\n",
    "            ku = self.kappa * u_plus\n",
    "            exp_ku = torch.exp(ku)\n",
    "            spalding_term = u_plus + torch.exp(torch.tensor(-self.kappa * self.B, device=u_plus.device, dtype=u_plus.dtype)) * (\n",
    "                exp_ku - 1 - ku - 0.5 * ku**2 - (1/6) * ku**3\n",
    "            )\n",
    "            rhs = (y_plus_grid_dist * u_mag_wall_parallel) / (nu_effective * u_plus.clamp(min=1e-8))\n",
    "            f_eq_solve = spalding_term - rhs\n",
    "\n",
    "            d_spalding_term = 1 + torch.exp(torch.tensor(-self.kappa * self.B, device=u_plus.device, dtype=u_plus.dtype)) * (\n",
    "                self.kappa * exp_ku - self.kappa - self.kappa**2 * u_plus - 0.5 * self.kappa**3 * u_plus**2\n",
    "            )\n",
    "            d_rhs = - (y_plus_grid_dist * u_mag_wall_parallel) / (nu_effective * u_plus.clamp(min=1e-8)**2)\n",
    "            df_eq_solve = d_spalding_term - d_rhs\n",
    "\n",
    "            delta = f_eq_solve / torch.where(torch.abs(df_eq_solve) < 1e-10, torch.tensor(1e-10, device=f_eq_solve.device), df_eq_solve)\n",
    "            u_plus = (u_plus - delta).clamp(min=1e-4)\n",
    "\n",
    "            if torch.max(torch.abs(delta)) < self.tol:\n",
    "                break\n",
    "        return u_plus\n",
    "\n",
    "    def __call__(self, f_full_grid):\n",
    "        rho_full = self.lattice.rho(f_full_grid)\n",
    "        u_full = self.lattice.u(f_full_grid)\n",
    "\n",
    "        if rho_full.ndim == self.lattice.D + 1 and rho_full.shape[0] == 1:\n",
    "            rho_full = rho_full.squeeze(0)\n",
    "        if u_full.ndim == self.lattice.D + 1 and u_full.shape[1] == 1:\n",
    "            u_full = u_full.squeeze(1)\n",
    "\n",
    "        grid_spatial_dims = list(range(self.lattice.D))\n",
    "        spatial_idx_slice = [slice(None)] * self.lattice.D\n",
    "        spatial_idx_slice[self.normal_axis] = 1 if self.wall == \"bottom\" else -2\n",
    "\n",
    "        rho_f = rho_full[tuple(spatial_idx_slice)].flatten()\n",
    "        u_x_f = u_full[0][tuple(spatial_idx_slice)].flatten()\n",
    "        u_y_f = u_full[1][tuple(spatial_idx_slice)].flatten()\n",
    "        u_z_f = u_full[2][tuple(spatial_idx_slice)].flatten() if self.lattice.D == 3 else torch.zeros_like(u_x_f)\n",
    "\n",
    "        u_mag_wall_parallel = torch.sqrt(u_x_f**2 + u_z_f**2).clamp(min=1e-10)\n",
    "\n",
    "        if self.use_smagorinsky:\n",
    "            tau_eff_scalar = self.smagorinsky_collision.tau_eff\n",
    "            shape = u_full[0].shape\n",
    "            tau_eff_full_grid = torch.full(shape, tau_eff_scalar, device=u_full.device, dtype=u_full.dtype)\n",
    "            nu_eff_full_grid = (tau_eff_full_grid - 0.5) / 3.0\n",
    "            nu_eff_wall_layer = nu_eff_full_grid[tuple(spatial_idx_slice)].flatten()\n",
    "        else:\n",
    "            nu_eff_wall_layer = torch.full_like(u_mag_wall_parallel, self.nu)\n",
    "\n",
    "        u_plus = self.spalding_law(self.y, u_mag_wall_parallel, nu_eff_wall_layer)\n",
    "        u_tau = (u_mag_wall_parallel / u_plus).clamp(min=1e-8)\n",
    "        tau_w = rho_f * u_tau**2\n",
    "\n",
    "        safe_u_mag = torch.where(u_mag_wall_parallel < 1e-10, torch.tensor(1.0, device=u_mag_wall_parallel.device, dtype=u_mag_wall_parallel.dtype), u_mag_wall_parallel)\n",
    "        tau_x = - (u_x_f / safe_u_mag) * tau_w\n",
    "        tau_z = - (u_z_f / safe_u_mag) * tau_w\n",
    "\n",
    "        tau_x_wall = torch.zeros_like(u_full[0])\n",
    "        tau_z_wall = torch.zeros_like(u_full[2] if self.lattice.D == 3 else u_full[0])\n",
    "\n",
    "        if self.lattice.D == 3:\n",
    "            target_shape_slice = tau_x_wall[tuple(spatial_idx_slice)].shape\n",
    "            tau_x_wall[tuple(spatial_idx_slice)] = tau_x.reshape(target_shape_slice)\n",
    "            tau_z_wall[tuple(spatial_idx_slice)] = tau_z.reshape(target_shape_slice)\n",
    "        else:\n",
    "            raise ValueError(\"Only 3D supported for this current implementation of WallQuantitiesInternal.\")\n",
    "\n",
    "        return {\n",
    "            \"tau_x\": tau_x_wall,\n",
    "            \"tau_z\": tau_z_wall,\n",
    "            \"u_tau\": u_tau\n",
    "        }\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-24T15:47:00.087098244Z",
     "start_time": "2025-06-24T15:47:00.084212844Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "\n",
    "class WallFunctionBoundaryTest:\n",
    "    def __init__(self, mask, lattice, flow, wall='bottom',\n",
    "                 kappa=0.41, B=5.2, max_iter=100, tol=1e-8):\n",
    "        self.mask = lattice.convert_to_tensor(mask)\n",
    "        self.lattice = lattice\n",
    "        self.flow = flow\n",
    "        self.wall = wall\n",
    "        self.kappa = kappa\n",
    "        self.B = B\n",
    "        self.max_iter = max_iter\n",
    "        self.tol = tol\n",
    "\n",
    "        self.tau_x = None # Diese können immer noch None sein, da es Felder sind und später gesetzt werden\n",
    "        self.tau_z = None\n",
    "\n",
    "        # 🛑🛑🛑 DIES IST DIE ENTSCHEIDENDE ÄNDERUNG! 🛑🛑🛑\n",
    "        # Initialisiere alle relevanten Mittelwerte mit einem gültigen Tensor-Wert (z.B. 0.0)\n",
    "        # Das ist wichtig, damit Attribute.item() und andere Operationen fehlschlagen.\n",
    "        self.u_tau_mean = torch.tensor(0.0, device=lattice.device, dtype=lattice.dtype)\n",
    "        self.y_plus_mean = torch.tensor(0.0, device=lattice.device, dtype=lattice.dtype)\n",
    "        self.Re_tau_mean = torch.tensor(0.0, device=lattice.device, dtype=lattice.dtype)\n",
    "        self.previous_u_tau_mean = torch.tensor(0.0, device=lattice.device, dtype=lattice.dtype) # Auch diese initialisieren!\n",
    "        # 🛑🛑🛑 ENDE DER ENTSCHEIDENDEN ÄNDERUNG 🛑🛑🛑\n",
    "\n",
    "    def spalding_law(self, y_plus_target):\n",
    "        # Der Code hier bleibt, wie ich ihn in der letzten Antwort vorgeschlagen habe,\n",
    "        # mit den Robustheits-Checks auf NaN/Inf etc.\n",
    "        # Stellen Sie sicher, dass Sie diese Version verwenden.\n",
    "        u_plus = torch.ones_like(y_plus_target, device=y_plus_target.device)  # Startwert\n",
    "\n",
    "        A = torch.exp(torch.tensor(-self.kappa * self.B, device=y_plus_target.device, dtype=y_plus_target.dtype))\n",
    "\n",
    "        # --- Check: Input y_plus_target auf NaN/Inf prüfen ---\n",
    "        if torch.isnan(y_plus_target).any() or torch.isinf(y_plus_target).any() or (y_plus_target <= 0).any():\n",
    "            return torch.full_like(y_plus_target, 1.0) # Oder einen anderen sicheren Standardwert, z.B. y_plus_target.clamp(min=1e-4) / self.kappa\n",
    "\n",
    "        for i in range(self.max_iter):\n",
    "            ku = self.kappa * u_plus\n",
    "            exp_ku = torch.exp(ku)\n",
    "\n",
    "            lhs = u_plus + A * (exp_ku - 1 - ku - 0.5 * ku**2 - (1/6) * ku**3)\n",
    "            rhs = y_plus_target\n",
    "            residual = lhs - rhs\n",
    "\n",
    "            # Stärkere Absicherung gegen Division durch Null oder sehr kleine Werte\n",
    "            d_lhs = 1 + A * (self.kappa * exp_ku - self.kappa - self.kappa**2 * u_plus - 0.5 * self.kappa**3 * u_plus**2)\n",
    "            d_lhs_safe = torch.where(torch.abs(d_lhs) < 1e-15, torch.tensor(1e-15, device=d_lhs.device, dtype=d_lhs.dtype), d_lhs) # Kleinen Wert hinzufügen\n",
    "            delta = residual / d_lhs_safe\n",
    "            u_plus_new = (u_plus - delta).clamp(min=1e-4) # Absichern gegen zu kleine Werte\n",
    "\n",
    "            # Prüfen auf NaN/Inf nach Update\n",
    "            if torch.isnan(u_plus_new).any() or torch.isinf(u_plus_new).any():\n",
    "                return u_plus # Kehre zum letzten stabilen Wert zurück oder einen Default\n",
    "\n",
    "            if torch.max(torch.abs(delta)) < self.tol:\n",
    "                break\n",
    "\n",
    "            u_plus = u_plus_new\n",
    "\n",
    "        # --- Check: u_plus am Ende auf NaN/Inf prüfen ---\n",
    "        if torch.isnan(u_plus).any() or torch.isinf(u_plus).any():\n",
    "            return torch.full_like(y_plus_target, 1.0)\n",
    "\n",
    "        return u_plus\n",
    "\n",
    "\n",
    "    def __call__(self, f):\n",
    "\n",
    "        if self.wall == 'bottom':\n",
    "            f17_old = f[17, self.mask].clone()\n",
    "            f16_old = f[16, self.mask].clone()\n",
    "            f10_old = f[10, self.mask].clone()\n",
    "            f8_old  = f[8, self.mask].clone()\n",
    "        elif self.wall == 'top':\n",
    "            f15_old = f[15, self.mask].clone()\n",
    "            f18_old = f[18, self.mask].clone()\n",
    "            f7_old  = f[7, self.mask].clone()\n",
    "            f9_old  = f[9, self.mask].clone()\n",
    "        else:\n",
    "            raise ValueError(\"wall must be 'bottom' or 'top'\")\n",
    "\n",
    "        try:\n",
    "            # --- 2. Wall Quantities berechnen ---\n",
    "            rho = self.lattice.rho(f[:,self.mask])\n",
    "            u = self.lattice.u(f)\n",
    "            u_x = u[0][self.mask]\n",
    "            u_z = u[2][self.mask] if self.lattice.D == 3 else torch.zeros_like(u_x)\n",
    "            u_mag_parallel = torch.sqrt(u_x**2 + u_z**2).clamp(min=1e-10) # Sicherstellen > 0\n",
    "\n",
    "            y = torch.tensor(1.0, device=f.device, dtype=f.dtype)  # Wandabstand 1 LU\n",
    "            nu = torch.tensor(self.flow.units.viscosity_lu, device=f.device, dtype=f.dtype)\n",
    "\n",
    "            # --- Check: Viskosität nu auf Gültigkeit prüfen ---\n",
    "            if nu <= 0 or torch.isnan(nu) or torch.isinf(nu):\n",
    "                # Auch hier sicherstellen, dass previous_u_tau_mean gesetzt wird\n",
    "                # Da es jetzt initialisiert ist, können wir es klonen.\n",
    "                self.previous_u_tau_mean = self.u_tau_mean.clone().detach()\n",
    "                self.u_tau_mean = torch.tensor(0.0, device=f.device, dtype=f.dtype)\n",
    "                self.y_plus_mean = torch.tensor(0.0, device=f.device, dtype=f.dtype)\n",
    "                self.Re_tau_mean = torch.tensor(0.0, device=f.device, dtype=f.dtype)\n",
    "                return f # Beende die Funktion frühzeitig im Fehlerfall\n",
    "\n",
    "            y_plus_target = y * u_mag_parallel / nu\n",
    "\n",
    "            u_plus = self.spalding_law(y_plus_target)\n",
    "\n",
    "            # --- Check: u_plus Ergebnis aus Spalding Law prüfen ---\n",
    "            if torch.isnan(u_plus).any() or torch.isinf(u_plus).any() or (u_plus <= 0).any():\n",
    "                self.previous_u_tau_mean = self.u_tau_mean.clone().detach()\n",
    "                self.u_tau_mean = torch.tensor(0.0, device=f.device, dtype=f.dtype)\n",
    "                self.y_plus_mean = torch.tensor(0.0, device=f.device, dtype=f.dtype)\n",
    "                self.Re_tau_mean = torch.tensor(0.0, device=f.device, dtype=f.dtype)\n",
    "                return f # Beende die Funktion frühzeitig im Fehlerfall\n",
    "\n",
    "            u_tau = u_mag_parallel / u_plus\n",
    "            tau_w = rho * u_tau**2\n",
    "\n",
    "            # --- Check: tau_w auf NaN/Inf prüfen ---\n",
    "            if torch.isnan(tau_w).any() or torch.isinf(tau_w).any():\n",
    "                self.previous_u_tau_mean = self.u_tau_mean.clone().detach()\n",
    "                self.u_tau_mean = torch.tensor(0.0, device=f.device, dtype=f.dtype)\n",
    "                self.y_plus_mean = torch.tensor(0.0, device=f.device, dtype=f.dtype)\n",
    "                self.Re_tau_mean = torch.tensor(0.0, device=f.device, dtype=f.dtype)\n",
    "                return f # Beende die Funktion frühzeitig im Fehlerfall\n",
    "\n",
    "\n",
    "            safe_u = torch.where(u_mag_parallel < 1e-10, torch.tensor(1.0, device=f.device), u_mag_parallel)\n",
    "            tau_x = - (u_x / safe_u) * tau_w\n",
    "            tau_z = - (u_z / safe_u) * tau_w\n",
    "\n",
    "            tau_x_field = torch.zeros_like(u[0])\n",
    "            tau_z_field = torch.zeros_like(u[2] if self.lattice.D == 3 else u[0])\n",
    "\n",
    "            tau_x_field[self.mask] = tau_x\n",
    "            tau_z_field[self.mask] = tau_z\n",
    "\n",
    "            # --- Check: tau_x_field und tau_z_field auf NaN/Inf prüfen ---\n",
    "            if torch.isnan(tau_x_field).any() or torch.isinf(tau_x_field).any() or \\\n",
    "               torch.isnan(tau_z_field).any() or torch.isinf(tau_z_field).any():\n",
    "                self.previous_u_tau_mean = self.u_tau_mean.clone().detach()\n",
    "                self.u_tau_mean = torch.tensor(0.0, device=f.device, dtype=f.dtype)\n",
    "                self.y_plus_mean = torch.tensor(0.0, device=f.device, dtype=f.dtype)\n",
    "                self.Re_tau_mean = torch.tensor(0.0, device=f.device, dtype=f.dtype)\n",
    "                return f # Beende die Funktion frühzeitig im Fehlerfall\n",
    "\n",
    "            # --- 3. Free-Slip Bounce-Back anwenden ---\n",
    "            f = torch.where(self.mask, f[self.lattice.stencil.opposite], f)\n",
    "\n",
    "            # --- 4. Additive Wandkorrektur ---\n",
    "            if self.wall == 'bottom':\n",
    "                f[15, self.mask] = f17_old + tau_z_field[self.mask]\n",
    "                f[16, self.mask] = f17_old + tau_z_field[self.mask]\n",
    "                f[18, self.mask] = f16_old - tau_z_field[self.mask]\n",
    "                f[8,  self.mask] = f16_old - tau_z_field[self.mask]\n",
    "                f[7,  self.mask] = f10_old + tau_x_field[self.mask]\n",
    "                f[17, self.mask] = f10_old + tau_x_field[self.mask]\n",
    "                f[9,  self.mask] = f8_old - tau_x_field[self.mask]\n",
    "                f[10, self.mask] = f8_old - tau_x_field[self.mask]\n",
    "            elif self.wall == 'top':\n",
    "                f[17, self.mask] = f15_old + tau_z_field[self.mask]\n",
    "                f[18, self.mask] = f15_old + tau_z_field[self.mask]\n",
    "                f[16, self.mask] = f18_old - tau_z_field[self.mask]\n",
    "                f[9,  self.mask] = f18_old - tau_z_field[self.mask]\n",
    "                f[10, self.mask] = f7_old + tau_x_field[self.mask]\n",
    "                f[15, self.mask] = f7_old + tau_x_field[self.mask]\n",
    "                f[8,  self.mask] = f9_old - tau_x_field[self.mask]\n",
    "                f[7,  self.mask] = f9_old - tau_x_field[self.mask]\n",
    "\n",
    "            # --- 5. Ergebnisse speichern ---\n",
    "            self.tau_x = tau_x_field\n",
    "            self.tau_z = tau_z_field\n",
    "            # previous_u_tau_mean muss VOR der Aktualisierung von u_tau_mean gesetzt werden\n",
    "            self.previous_u_tau_mean = self.u_tau_mean.clone().detach() # Klonen, um Referenzprobleme zu vermeiden\n",
    "            self.u_tau_mean = u_tau.mean()\n",
    "            self.y_plus_mean = (y * u_tau / nu).mean()\n",
    "            self.Re_tau_mean = (u_tau * y / nu).mean()\n",
    "            if torch.isnan(self.u_tau_mean) or torch.isinf(self.u_tau_mean) or \\\n",
    "               torch.isnan(self.y_plus_mean) or torch.isinf(self.y_plus_mean) or \\\n",
    "               torch.isnan(self.Re_tau_mean) or torch.isinf(self.Re_tau_mean):\n",
    "                self.u_tau_mean = torch.tensor(0.0, device=f.device, dtype=f.dtype)\n",
    "                self.y_plus_mean = torch.tensor(0.0, device=f.device, dtype=f.dtype)\n",
    "                self.Re_tau_mean = torch.tensor(0.0, device=f.device, dtype=f.dtype)\n",
    "\n",
    "        except Exception as e:\n",
    "            # Im Fehlerfall alle wichtigen Größen auf sichere Defaults setzen\n",
    "            # Stellen Sie sicher, dass previous_u_tau_mean auch hier sicher gesetzt wird.\n",
    "            self.previous_u_tau_mean = self.u_tau_mean.clone().detach() if self.u_tau_mean is not None else torch.tensor(0.0, device=f.device, dtype=f.dtype)\n",
    "            self.u_tau_mean = torch.tensor(0.0, device=f.device, dtype=f.dtype)\n",
    "            self.y_plus_mean = torch.tensor(0.0, device=f.device, dtype=f.dtype)\n",
    "            self.Re_tau_mean = torch.tensor(0.0, device=f.device, dtype=f.dtype)\n",
    "\n",
    "        return f\n",
    "\n",
    "    def make_no_collision_mask(self, f_shape):\n",
    "        assert self.mask.shape == f_shape[1:]\n",
    "        return self.mask"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-24T15:47:00.157588310Z",
     "start_time": "2025-06-24T15:47:00.151164960Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "class WallFunctionBoundaryTest2:\n",
    "    def __init__(self, mask, lattice, flow, wall='bottom', apply_wfb_correction=True,\n",
    "                 smagorinsky_collision_instance=None):\n",
    "        self.mask = lattice.convert_to_tensor(mask)\n",
    "        self.lattice = lattice\n",
    "        self.flow = flow\n",
    "        self.wall = wall\n",
    "        self.apply_wfb_correction = apply_wfb_correction\n",
    "        self.normal_axis = 1\n",
    "\n",
    "        self.tau_x = None\n",
    "        self.tau_z = None\n",
    "        self.u_tau_mean = None\n",
    "        self.y_plus_mean = None\n",
    "        self.Re_tau_mean = None\n",
    "\n",
    "        self.use_smagorinsky = smagorinsky_collision_instance is not None\n",
    "\n",
    "        # Konstruktion der WallQuantitiesInternal – immer\n",
    "        self.wall_quantities_internal = WallQuantitiesInternal(\n",
    "            lattice=self.lattice,\n",
    "            flow=self.flow,\n",
    "            molecular_viscosity=self.flow.units.viscosity_lu,\n",
    "            wall=self.wall,\n",
    "            y_lattice=1.0,\n",
    "            use_smagorinsky=self.use_smagorinsky,\n",
    "            smagorinsky_collision_instance=smagorinsky_collision_instance\n",
    "        )\n",
    "\n",
    "    def set_smagorinsky_collision(self, collision):\n",
    "        self.smagorinsky_collision = collision\n",
    "        self.wall_quantities_internal = WallQuantitiesInternal(\n",
    "            lattice=self.lattice,\n",
    "            flow=self.flow,\n",
    "            molecular_viscosity=self.flow.units.viscosity_lu,\n",
    "            wall=self.wall,\n",
    "            y_lattice=1.0,\n",
    "            smagorinsky_collision_instance=collision\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "    def __call__(self, f):\n",
    "        # --- 1. Klonen der Originalverteilungen für spätere Korrektur ---\n",
    "\n",
    "        if self.wall == 'bottom':\n",
    "            f17_old = f [17, self.mask].clone()\n",
    "            f16_old = f[16, self.mask].clone()\n",
    "            f10_old = f[10, self.mask].clone()\n",
    "            f8_old  = f[8, self.mask].clone()\n",
    "        elif self.wall == 'top':\n",
    "            f15_old = f[15, self.mask].clone()\n",
    "            f18_old = f[18, self.mask].clone()\n",
    "            f7_old  = f[7, self.mask].clone()\n",
    "            f9_old  = f[9, self.mask].clone()\n",
    "        else:\n",
    "            raise ValueError(\"wall must be 'bottom' or 'top'\")\n",
    "\n",
    "        # --- 2. Wall Quantities intern berechnen ---\n",
    "        results = self.wall_quantities_internal(f)\n",
    "        tau_x_field = 0.5 * results[\"tau_x\"]\n",
    "        tau_z_field = 0.5 * results[\"tau_z\"]\n",
    "\n",
    "        # --- 3. Free-Slip Bounce-Back anwenden ---\n",
    "        f = torch.where(self.mask, f[self.lattice.stencil.opposite], f)\n",
    "\n",
    "        # --- 4. Additive Wandkorrektur ---\n",
    "        if self.wall == 'bottom':\n",
    "            f[15, self.mask] = f17_old + tau_z_field[self.mask]\n",
    "            f[16, self.mask] = f17_old + tau_z_field[self.mask]\n",
    "            f[18, self.mask] = f16_old - tau_z_field[self.mask]\n",
    "            f[8,  self.mask] = f16_old - tau_z_field[self.mask]\n",
    "            f[7,  self.mask] = f10_old + tau_x_field[self.mask]\n",
    "            f[17, self.mask] = f10_old + tau_x_field[self.mask]\n",
    "            f[9,  self.mask] = f8_old - tau_x_field[self.mask]\n",
    "            f[10, self.mask] = f8_old - tau_x_field[self.mask]\n",
    "        elif self.wall == 'top':\n",
    "            f[17, self.mask] = f15_old + tau_z_field[self.mask]\n",
    "            f[18, self.mask] = f15_old + tau_z_field[self.mask]\n",
    "            f[16, self.mask] = f18_old - tau_z_field[self.mask]\n",
    "            f[9,  self.mask] = f18_old - tau_z_field[self.mask]\n",
    "            f[10, self.mask] = f7_old + tau_x_field[self.mask]\n",
    "            f[15, self.mask] = f7_old + tau_x_field[self.mask]\n",
    "            f[8,  self.mask] = f9_old - tau_x_field[self.mask]\n",
    "            f[7,  self.mask] = f9_old - tau_x_field[self.mask]\n",
    "\n",
    "        # --- 5. Ergebnisse für Reporter speichern ---\n",
    "        self.tau_x = tau_x_field\n",
    "        self.tau_z = tau_z_field\n",
    "\n",
    "\n",
    "        self.u_tau_mean = results[\"u_tau\"].mean()\n",
    "        self.previous_u_tau_mean = self.u_tau_mean.clone().detach()\n",
    "\n",
    "        self.y_plus_mean = (self.wall_quantities_internal.y * results[\"u_tau\"] / self.wall_quantities_internal.nu).mean()\n",
    "        self.Re_tau_mean = (results[\"u_tau\"] * self.wall_quantities_internal.y / self.wall_quantities_internal.nu).mean()\n",
    "\n",
    "        return f\n",
    "\n",
    "    def make_no_collision_mask(self, f_shape):\n",
    "        \"\"\"\n",
    "        Diese Boundary-Methode liefert die Maske der Wandknoten,\n",
    "        auf denen der Kollisionsschritt der Hauptsimulation übersprungen werden soll.\n",
    "        Diese Klasse operiert auf diesen Wandknoten selbst.\n",
    "        \"\"\"\n",
    "        assert self.mask.shape == f_shape[1:]\n",
    "        # KORREKTUR: Muss die Maske der eigenen Wandknoten (self.mask) zurückgeben.\n",
    "        return self.mask\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-24T15:47:00.164981531Z",
     "start_time": "2025-06-24T15:47:00.159954499Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "class ChannelFlow3DTest:\n",
    "    def __init__(self, resolution_x, resolution_y, resolution_z,\n",
    "                 reynolds_number, mach_number, lattice, char_length_lu,\n",
    "                 boundary=None,  # jetzt erlaubt: externe Übergabe\n",
    "                 boundaries=None  # neu: direkt übergebene Instanzen\n",
    "                 ):\n",
    "        self.resolution_x = resolution_x\n",
    "        self.resolution_y = resolution_y\n",
    "        self.resolution_z = resolution_z\n",
    "        self._boundary = boundary  # z. B. \"wallfunction\"\n",
    "        self._external_boundaries = boundaries  # die Instanzen direkt\n",
    "        self._boundaries = None  # wird ggf. erzeugt\n",
    "\n",
    "        self.units = UnitConversion(\n",
    "            lattice,\n",
    "            reynolds_number=reynolds_number,\n",
    "            mach_number=mach_number,\n",
    "            characteristic_length_lu=char_length_lu,\n",
    "            characteristic_length_pu=1,\n",
    "            characteristic_velocity_pu=1\n",
    "        )\n",
    "\n",
    "        self._mask = np.zeros(shape=(self.resolution_x, self.resolution_y, self.resolution_z), dtype=bool)\n",
    "    @property\n",
    "    def mask(self):\n",
    "        return self._mask\n",
    "\n",
    "    @mask.setter\n",
    "    def mask(self, m):\n",
    "        assert isinstance(m, np.ndarray) and m.shape == (self.resolution_x, self.resolution_y, self.resolution_z)\n",
    "        self._mask = m.astype(bool)\n",
    "\n",
    "    def initial_solution(self, grid):\n",
    "        xg, yg, zg = grid\n",
    "        p = np.ones_like(xg)[None, ...]\n",
    "        nx, ny, nz = self.resolution_x, self.resolution_y, self.resolution_z\n",
    "\n",
    "        u = np.zeros((3, nx, ny, nz))\n",
    "\n",
    "        # --- 📐 Poiseuille-Profil (in x-Richtung) ---\n",
    "        y_normalized = yg / yg.max()\n",
    "        u_base = y_normalized * (1 - y_normalized)\n",
    "        u[0] = u_base * (1 - self.mask.astype(float))  # u_x = Basisströmung\n",
    "\n",
    "        # --- 🎛️ Sinusmoden-Störung (3D) ---\n",
    "        A_sin = 0.5  # 5% Amplitude\n",
    "        Lx, Ly, Lz = xg.max(), yg.max(), zg.max()\n",
    "        sinus_modes = [(1, 1, 1), (2, 2, 3), (3, 2, 1)]\n",
    "\n",
    "        for kx, ky, kz in sinus_modes:\n",
    "            phase = 2 * np.pi * np.random.rand()\n",
    "            mode = np.sin(2 * np.pi * (kx * xg / Lx + ky * yg / Ly + kz * zg / Lz) + phase)\n",
    "            envelope = y_normalized * (1 - y_normalized)\n",
    "            u[0] += A_sin * mode * envelope  # nur u_x gestört, kannst du erweitern\n",
    "\n",
    "        # --- 🌪️ Vektorpotential ψ (3 Komponenten für Curl in 3D) ---\n",
    "        A_psi = 1\n",
    "        random_psi = ((np.random.rand(3, nx, ny, nz) - 0.5) * 2)\n",
    "\n",
    "        # Wandgewichtung in y und z\n",
    "        y_weight = np.exp(-((y_normalized - 0.0) / 0.2) ** 2) + np.exp(-((y_normalized - 1.0) / 0.2) ** 2)\n",
    "        y_weight /= y_weight.max()\n",
    "\n",
    "        z_normalized = zg / zg.max()\n",
    "        z_weight = np.exp(-((z_normalized - 0.5) / 0.3) ** 2)\n",
    "        z_weight /= z_weight.max()\n",
    "\n",
    "        weight = y_weight * z_weight\n",
    "        random_psi *= weight[None, :, :, :]\n",
    "\n",
    "        # FFT-Filterung (3D)\n",
    "        k0 = np.sqrt(nx ** 2 + ny ** 2 + nz ** 2)\n",
    "        psi_filtered = np.empty_like(random_psi)\n",
    "        for d in range(3):\n",
    "            psi_hat = np.fft.fftn(random_psi[d])\n",
    "            kx = np.fft.fftfreq(nx).reshape(-1, 1, 1)\n",
    "            ky = np.fft.fftfreq(ny).reshape(1, -1, 1)\n",
    "            kz = np.fft.fftfreq(nz).reshape(1, 1, -1)\n",
    "            kabs = np.sqrt((kx * nx) ** 2 + (ky * ny) ** 2 + (kz * nz) ** 2)\n",
    "            filter_mask = np.exp(-kabs / (0.3 * k0))\n",
    "            psi_hat *= filter_mask\n",
    "            psi_hat[0, 0, 0] = 0\n",
    "            psi_filtered[d] = np.real(np.fft.ifftn(psi_hat))\n",
    "\n",
    "        # --- 🌀 Curl(ψ): u = ∇ × ψ ---\n",
    "        u_psi = np.zeros_like(u)\n",
    "        u_psi[0] = np.gradient(psi_filtered[2], axis=1) - np.gradient(psi_filtered[1], axis=2)  # u_x\n",
    "        u_psi[1] = np.gradient(psi_filtered[0], axis=2) - np.gradient(psi_filtered[2], axis=0)  # u_y\n",
    "        u_psi[2] = np.gradient(psi_filtered[1], axis=0) - np.gradient(psi_filtered[0], axis=1)  # u_z\n",
    "\n",
    "        # Normierung\n",
    "        umax_psi = np.max(np.sqrt(np.sum(u_psi ** 2, axis=0)))\n",
    "        if umax_psi > 0:\n",
    "            u_psi *= A_psi / umax_psi\n",
    "\n",
    "        # --- Überlagerung: Basis + Sine + Curl ---\n",
    "        u += u_psi\n",
    "        # 2D: Nullsetzen der Wandgeschwindigkeit\n",
    "\n",
    "        u[:, :, 0, :] = 0.0  # untere Wand (y=0)\n",
    "        u[:, :, -1, :] = 0.0  # obere Wand (y=Ny-1)\n",
    "\n",
    "        return p, u\n",
    "\n",
    "    @property\n",
    "    def grid(self):\n",
    "        stop_x = self.resolution_x / self.units.characteristic_length_lu\n",
    "        stop_y = self.resolution_y / self.units.characteristic_length_lu\n",
    "        stop_z = self.resolution_z / self.units.characteristic_length_lu\n",
    "\n",
    "        x = np.linspace(0, stop_x, num=self.resolution_x, endpoint=False)\n",
    "        y = np.linspace(0, stop_y, num=self.resolution_y, endpoint=False)\n",
    "        z = np.linspace(0, stop_z, num=self.resolution_z, endpoint=False)\n",
    "\n",
    "        return np.meshgrid(x, y, z, indexing='ij')\n",
    "\n",
    "    @property\n",
    "    def boundaries(self):\n",
    "\n",
    "        return self._external_boundaries"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-24T15:47:00.218977452Z",
     "start_time": "2025-06-24T15:47:00.175083117Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "class WallQuantitiesTest:\n",
    "    def __init__(self, lattice, flow, boundary):\n",
    "        self.lattice = lattice\n",
    "        self.flow = flow\n",
    "        self.boundary = boundary\n",
    "\n",
    "    def __call__(self, f):\n",
    "        try:\n",
    "            # Hier die hasattr-Prüfung ENTFERNEN. Die Attribute existieren jetzt immer, da sie in __init__\n",
    "            # von WallFunctionBoundaryTest mit 0.0 initialisiert werden.\n",
    "\n",
    "            # Stattdessen prüfen, ob die Werte noch die initialen Nullen sind oder NaN/Inf\n",
    "            # (assuming WallFunctionBoundaryTest initializes to torch.tensor(0.0))\n",
    "            if (self.boundary.u_tau_mean.item() == 0.0 and self.boundary.y_plus_mean.item() == 0.0 and self.boundary.Re_tau_mean.item() == 0.0) or \\\n",
    "               torch.isnan(self.boundary.u_tau_mean) or torch.isinf(self.boundary.u_tau_mean):\n",
    "                return torch.zeros(3, dtype=f.dtype, device=f.device)\n",
    "\n",
    "            u_tau_mean = self.boundary.u_tau_mean\n",
    "            y_plus_mean = self.boundary.y_plus_mean\n",
    "            re_tau_mean = self.boundary.Re_tau_mean\n",
    "\n",
    "\n",
    "            return torch.stack([\n",
    "                u_tau_mean,\n",
    "                y_plus_mean,\n",
    "                re_tau_mean,\n",
    "            ])\n",
    "\n",
    "        except Exception as e:\n",
    "            return torch.zeros(3, dtype=f.dtype, device=f.device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-24T15:47:00.219239126Z",
     "start_time": "2025-06-24T15:47:00.218748678Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ICH FUNKTIONIERE MIT PULLEN\n"
     ]
    }
   ],
   "source": [
    "from argparse import ArgumentParser, ArgumentDefaultsHelpFormatter\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "parser = ArgumentParser(formatter_class=ArgumentDefaultsHelpFormatter)\n",
    "parser.add_argument(\"--vtkdir\", type=str, default=\"./output/\")\n",
    "parser.add_argument(\"--csvdir\", type=str, default=\"./output/\")\n",
    "parser.add_argument(\"--nout\", type=int, default=100)\n",
    "parser.add_argument(\"--nvtk\", type=int, default=100)\n",
    "parser.add_argument(\"--tmax\", type=int, default=0.1)\n",
    "parser.add_argument(\"--Re\", type=int, default=13800)\n",
    "parser.add_argument(\"--collision_operator\", type=str, default=\"BGK\")\n",
    "parser.add_argument(\"--Precision\", type=str, default=\"Double\")\n",
    "parser.add_argument(\"--Mach\", type=float, default=0.1)\n",
    "parser.add_argument(\"--h\", type=int, default=20, help=\"Halbe Kanalhöhe in LU\")\n",
    "parser.add_argument(\"--bbtype\", type=str, default=\"wallfunction\", choices=[\"halfway\", \"fullway\", \"wallfunction\", \"freeslip\"],\n",
    "                    help=\"Typ der Bounce-Back-Randbedingung\")\n",
    "\n",
    "args, unknown = parser.parse_known_args()\n",
    "args = vars(args)\n",
    "\n",
    "print(\"ICH FUNKTIONIERE MIT PULLEN\")\n",
    "\n",
    "\n",
    "\n",
    "# Einheiten und Auflösung\n",
    "h = args[\"h\"]                      # Kanalhalbhöhe in LU\n",
    "res_y = 2 * h                     # y: volle Kanalhöhe\n",
    "res_x = int(2*np.pi * h)\n",
    "res_z = int(np.pi * h)\n",
    "\n",
    "# Restliche Parameter\n",
    "Re = args[\"Re\"]\n",
    "basedir = args[\"vtkdir\"]\n",
    "csvdir = args[\"csvdir\"]\n",
    "nout = args[\"nout\"]\n",
    "nvtk = args[\"nvtk\"]\n",
    "tmax = args[\"tmax\"]\n",
    "Precision = args[\"Precision\"]\n",
    "collision_operator = args[\"collision_operator\"]\n",
    "Mach = args[\"Mach\"]\n",
    "bbtype = args[\"bbtype\"]\n",
    "# Präzision\n",
    "if Precision == \"Single\":\n",
    "    dtype = torch.float32\n",
    "elif Precision == \"Double\":\n",
    "    dtype = torch.float64\n",
    "elif Precision == \"Half\":\n",
    "    dtype = torch.float16\n",
    "\n",
    "\n",
    "Re_tau = 180\n",
    "\n",
    "smagorinsky_constant = 0.17\n",
    "\n",
    "delta_x = 1.0"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-24T15:47:00.219541059Z",
     "start_time": "2025-06-24T15:47:00.219187375Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA ist nicht verfügbar. Verwende CPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ben/anaconda3/envs/lettuce/lib/python3.11/site-packages/torch/cuda/__init__.py:138: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at /opt/conda/conda-bld/pytorch_1695392035891/work/c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steps     time     GlobalMeanUXReporter\n",
      "steps     time     WallQuantities\n",
      "steps     time     WallQuantities\n",
      "steps     time     IncompressibleKineticEnergy\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "# CUDA & Präzision\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "    print(\"CUDA ist verfügbar. Verwende GPU.\")\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "    print(\"CUDA ist nicht verfügbar. Verwende CPU.\")\n",
    "\n",
    "dtype = torch.float64  # Für Stabilität bei hohen Re\n",
    "lattice = Lattice(D3Q19(), device=device, dtype=dtype)\n",
    "\n",
    "# 🧱 Domänenmaße & Setup\n",
    "h = args[\"h\"]\n",
    "res_y = 2 * h\n",
    "res_x = int(2 * np.pi * h)\n",
    "res_z = int(np.pi * h)\n",
    "\n",
    "# 👇 Maske für Wandfunktion vorbereiten\n",
    "grid_x, grid_y, grid_z = np.meshgrid(\n",
    "    np.arange(res_x), np.arange(res_y), np.arange(res_z), indexing='ij'\n",
    ")\n",
    "\n",
    "mask_bottom = np.zeros_like(grid_x, dtype=bool)\n",
    "mask_bottom[:, 0, :] = True  # Erste Fluidzelle oben\n",
    "\n",
    "mask_top = np.zeros_like(grid_x, dtype=bool)\n",
    "mask_top[:, -1, :] = True  # Erste Fluidzelle unten\n",
    "\n",
    "# 🔧 Boundaries manuell erzeugen\n",
    "wfb_bottom = WallFunctionBoundaryTest(mask=mask_bottom, lattice=lattice, flow=None, wall='bottom')\n",
    "wfb_top    = WallFunctionBoundaryTest(mask=mask_top,    lattice=lattice, flow=None, wall='top')\n",
    "\n",
    "# 🌊 Flow erzeugen, Boundaries übergeben\n",
    "flow = ChannelFlow3DTest(\n",
    "    resolution_x=res_x,\n",
    "    resolution_y=res_y,\n",
    "    resolution_z=res_z,\n",
    "    reynolds_number=Re,\n",
    "    mach_number=Mach,\n",
    "    lattice=lattice,\n",
    "    char_length_lu=res_y,\n",
    "    boundaries=[wfb_bottom, wfb_top]\n",
    ")\n",
    "\n",
    "# 🧩 Boundaries kennen jetzt den Flow\n",
    "wfb_bottom.flow = flow\n",
    "wfb_top.flow = flow\n",
    "\n",
    "# 🧠 Check: IDs vergleichen\n",
    "\n",
    "# 📈 Reporter: Global Mean Ux\n",
    "global_mean_ux_reporter = lt.GlobalMeanUXReporter(lattice, flow)\n",
    "\n",
    "# 📊 Wall Quantities Reporter (lesen von denselben Objekten)\n",
    "wq_bottom = lt.WallQuantities(lattice=lattice, flow=flow, boundary=wfb_bottom)\n",
    "wq_top = lt.WallQuantities(lattice=lattice, flow=flow, boundary=wfb_top)\n",
    "\n",
    "\n",
    "\n",
    "# 🌀 Adaptive Force mit denselben Boundaries\n",
    "adaptive_force_instance = lt.AdaptiveForce(\n",
    "    lattice=lattice,\n",
    "    flow=flow,\n",
    "    target_u_m_lu=flow.units.convert_velocity_to_lu(1.0),\n",
    "    wall_bottom=wfb_bottom,\n",
    "    wall_top=wfb_top,\n",
    "    global_ux_reporter=global_mean_ux_reporter,\n",
    "    base_lbm_tau_lu=flow.units.relaxation_parameter_lu\n",
    ")\n",
    "\n",
    "# ⚙️ Kollision & Simulation\n",
    "collision = lt.BGKCollision(lattice, tau=flow.units.relaxation_parameter_lu, force=adaptive_force_instance)\n",
    "\n",
    "\n",
    "streaming = lt.StandardStreaming(lattice)\n",
    "\n",
    "\n",
    "\n",
    "simulation = lt.Simulation(flow=flow, lattice=lattice, collision=collision, streaming=streaming)\n",
    "\n",
    "\n",
    "\n",
    "# 📤 Reporter einfügen\n",
    "simulation.reporters.append(lt.ObservableReporter(global_mean_ux_reporter, interval=1, out=None))\n",
    "simulation.reporters.append(lt.ObservableReporter(wq_bottom, interval=1, out=None))\n",
    "simulation.reporters.append(lt.ObservableReporter(wq_top, interval=1, out=None))\n",
    "simulation.reporters.append(lt.ObservableReporter(lt.observables.IncompressibleKineticEnergy(lattice, flow), interval=100, out=None))\n",
    "\n",
    "# 📦 VTK\n",
    "steps = int(flow.units.convert_time_to_lu(tmax))\n",
    "vtk_reporter = lt.VTKReporter(lattice=lattice, flow=flow, interval=max(1, int(steps/100)), filename_base=basedir + \"/output\")\n",
    "simulation.reporters.append(vtk_reporter)\n",
    "\n",
    "# ▶️ Simulation starten\n",
    "simulation.initialize_f_neq()\n",
    "mlups = simulation.step(num_steps=steps)\n",
    "\n",
    "# 🧾 Ergebnisse abspeichern\n",
    "wq_top_arr = np.array(simulation.reporters[2].out)\n",
    "wq_bottom_arr = np.array(simulation.reporters[1].out)\n",
    "ux_mean_arr = np.array(simulation.reporters[0].out)\n",
    "\n",
    "with open(csvdir + 'uxmean.csv', 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerows(ux_mean_arr)\n",
    "with open(csvdir + 'WallQuantitiesTop.csv', 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerows(wq_top_arr)\n",
    "with open(csvdir + 'WallQuantitiesBottom.csv', 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerows(wq_bottom_arr)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-24T15:47:26.616604058Z",
     "start_time": "2025-06-24T15:47:00.221342192Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.WallFunctionBoundaryTest object at 0x7f736a2e80d0>\n",
      "<__main__.WallFunctionBoundaryTest object at 0x7f736a2e80d0>\n"
     ]
    }
   ],
   "source": [
    "print((wq_bottom.boundary))\n",
    "print((flow.boundaries[0]))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-24T15:47:26.618496523Z",
     "start_time": "2025-06-24T15:47:26.616801857Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'WallQuantities' and 'WallQuantities'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[10], line 5\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mnp\u001B[39;00m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;66;03m# Beispiel: Daten laden\u001B[39;00m\n\u001B[0;32m----> 5\u001B[0m data \u001B[38;5;241m=\u001B[39m (\u001B[43mwq_bottom\u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43mwq_top\u001B[49m)\u001B[38;5;241m/\u001B[39m\u001B[38;5;241m2\u001B[39m\n\u001B[1;32m      6\u001B[0m time \u001B[38;5;241m=\u001B[39m data[:, \u001B[38;5;241m1\u001B[39m]\n\u001B[1;32m      7\u001B[0m re_tau \u001B[38;5;241m=\u001B[39m data[:, \u001B[38;5;241m5\u001B[39m]\n",
      "\u001B[0;31mTypeError\u001B[0m: unsupported operand type(s) for +: 'WallQuantities' and 'WallQuantities'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Beispiel: Daten laden\n",
    "data = (wq_bottom+wq_top)/2\n",
    "time = data[:, 1]\n",
    "re_tau = data[:, 5]\n",
    "y_plus = data[:, 6]\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(time, re_tau, label=\"Re_tau (bottom)\")\n",
    "plt.xlabel(\"Zeit\")\n",
    "plt.ylabel(\"Re_tau\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.title(\"Re_tau über die Zeit\")\n",
    "plt.savefig(csvdir + \"retau.pdf\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(time, y_plus, label=\"y⁺ (bottom)\")\n",
    "plt.xlabel(\"Zeit\")\n",
    "plt.ylabel(\"y⁺\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.title(\"y⁺ über die Zeit\")\n",
    "plt.savefig(csvdir + \"yplus.pdf\")\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-24T15:47:26.886364905Z",
     "start_time": "2025-06-24T15:47:26.619831920Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
